{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "895cff1c",
      "metadata": {
        "id": "895cff1c"
      },
      "source": [
        "# Multi-Label Classification: Google Quest Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IST664 Natural Language Processing: Group 4: Project"
      ],
      "metadata": {
        "id": "2qIF6QGeFy3V"
      },
      "id": "2qIF6QGeFy3V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Sharvil Arjunwadkar<br>\n",
        "Aadil Zikre<br>\n",
        "Vipul Sarode<br>\n",
        "Gowtham Behara<br>\n",
        "Sai Naga Venkata Lakshmi Kalyan Medavarapu**\n"
      ],
      "metadata": {
        "id": "3ELo13JfjBhz"
      },
      "id": "3ELo13JfjBhz"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIEkcVntUtci",
        "outputId": "13b27c2f-53ed-4e8a-9e38-818ca0b6a2c1"
      },
      "id": "hIEkcVntUtci",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the required package\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1rUscLAuyJ",
        "outputId": "fd75ad1f-7993-49b1-ebd3-c8fef874b872"
      },
      "id": "YW1rUscLAuyJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9922406d",
      "metadata": {
        "id": "9922406d"
      },
      "source": [
        "### IMPORT REQUIRED PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79991681",
      "metadata": {
        "id": "79991681",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c58bd66-35ab-4f49-e028-37bf75912ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success\n"
          ]
        }
      ],
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import torch\n",
        "import torch.nn\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk import WordNetLemmatizer\n",
        "# import emoji\n",
        "\n",
        "# Utility functions from TF\n",
        "import keras\n",
        "import tensorflow as tf \n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import utils\n",
        "#from tensorflow.keras import preprocessing\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"Success\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2d9e8ad",
      "metadata": {
        "id": "c2d9e8ad"
      },
      "source": [
        "### DATA LOAD & PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd0fa14",
      "metadata": {
        "id": "8cd0fa14"
      },
      "outputs": [],
      "source": [
        "#import the dataset\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/NLP_Project/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d750a7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d750a7a",
        "outputId": "253d9cd4-7b0b-4900-f4f6-939ef0b8ab03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qa_id                                     question_title  \\\n",
              "0      0  What am I losing when using extension tubes in...   \n",
              "1      1  What is the distinction between a city and a s...   \n",
              "2      2  Maximum protusion length for through-hole comp...   \n",
              "3      3              Can an affidavit be used in Beit Din?   \n",
              "4      5       How do you make a binary image in Photoshop?   \n",
              "\n",
              "                                       question_body question_user_name  \\\n",
              "0  After playing around with macro photography on...               ysap   \n",
              "1  I am trying to understand what kinds of places...      russellpierce   \n",
              "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
              "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
              "4  I am trying to make a binary image. I want mor...            leigero   \n",
              "\n",
              "                                  question_user_page  \\\n",
              "0         https://photo.stackexchange.com/users/1024   \n",
              "1           https://rpg.stackexchange.com/users/8774   \n",
              "2  https://electronics.stackexchange.com/users/10157   \n",
              "3       https://judaism.stackexchange.com/users/5151   \n",
              "4  https://graphicdesign.stackexchange.com/users/...   \n",
              "\n",
              "                                              answer answer_user_name  \\\n",
              "0  I just got extension tubes, so here's the skin...           rfusca   \n",
              "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
              "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
              "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
              "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
              "\n",
              "                                    answer_user_page  \\\n",
              "0         https://photo.stackexchange.com/users/1917   \n",
              "1           https://rpg.stackexchange.com/users/1871   \n",
              "2  https://electronics.stackexchange.com/users/64754   \n",
              "3       https://judaism.stackexchange.com/users/4794   \n",
              "4  https://graphicdesign.stackexchange.com/users/...   \n",
              "\n",
              "                                                 url   category  ...  \\\n",
              "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
              "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
              "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
              "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
              "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
              "\n",
              "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
              "0              1.000000        1.000000                     0.666667   \n",
              "1              0.888889        0.888889                     0.555556   \n",
              "2              0.777778        0.777778                     0.555556   \n",
              "3              0.888889        0.833333                     0.333333   \n",
              "4              1.000000        1.000000                     0.666667   \n",
              "\n",
              "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
              "0          1.000000          1.000000             0.800000   \n",
              "1          0.888889          0.888889             0.666667   \n",
              "2          1.000000          1.000000             0.666667   \n",
              "3          0.833333          1.000000             0.800000   \n",
              "4          1.000000          1.000000             0.800000   \n",
              "\n",
              "   answer_type_instructions  answer_type_procedure  \\\n",
              "0                       1.0               0.000000   \n",
              "1                       0.0               0.000000   \n",
              "2                       0.0               0.333333   \n",
              "3                       0.0               0.000000   \n",
              "4                       1.0               0.000000   \n",
              "\n",
              "   answer_type_reason_explanation  answer_well_written  \n",
              "0                        0.000000             1.000000  \n",
              "1                        0.666667             0.888889  \n",
              "2                        1.000000             0.888889  \n",
              "3                        1.000000             1.000000  \n",
              "4                        1.000000             1.000000  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e43f0b9-be4f-4fe9-84ed-bd493797f138\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>...</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>ysap</td>\n",
              "      <td>https://photo.stackexchange.com/users/1024</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>rfusca</td>\n",
              "      <td>https://photo.stackexchange.com/users/1917</td>\n",
              "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>russellpierce</td>\n",
              "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>Erik Schmidt</td>\n",
              "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
              "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>...</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Joe Baker</td>\n",
              "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>Dwayne Reid</td>\n",
              "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
              "      <td>http://electronics.stackexchange.com/questions...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>...</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Scimonster</td>\n",
              "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>Y     e     z</td>\n",
              "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
              "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>...</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>leigero</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>q2ra</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e43f0b9-be4f-4fe9-84ed-bd493797f138')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e43f0b9-be4f-4fe9-84ed-bd493797f138 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e43f0b9-be4f-4fe9-84ed-bd493797f138');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "#View first 6 lines\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480b9848",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "480b9848",
        "outputId": "2cbf6352-30b6-4ec9-e51a-a1c08331d369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6079 entries, 0 to 6078\n",
            "Data columns (total 41 columns):\n",
            " #   Column                                 Non-Null Count  Dtype  \n",
            "---  ------                                 --------------  -----  \n",
            " 0   qa_id                                  6079 non-null   int64  \n",
            " 1   question_title                         6079 non-null   object \n",
            " 2   question_body                          6079 non-null   object \n",
            " 3   question_user_name                     6079 non-null   object \n",
            " 4   question_user_page                     6079 non-null   object \n",
            " 5   answer                                 6079 non-null   object \n",
            " 6   answer_user_name                       6079 non-null   object \n",
            " 7   answer_user_page                       6079 non-null   object \n",
            " 8   url                                    6079 non-null   object \n",
            " 9   category                               6079 non-null   object \n",
            " 10  host                                   6079 non-null   object \n",
            " 11  question_asker_intent_understanding    6079 non-null   float64\n",
            " 12  question_body_critical                 6079 non-null   float64\n",
            " 13  question_conversational                6079 non-null   float64\n",
            " 14  question_expect_short_answer           6079 non-null   float64\n",
            " 15  question_fact_seeking                  6079 non-null   float64\n",
            " 16  question_has_commonly_accepted_answer  6079 non-null   float64\n",
            " 17  question_interestingness_others        6079 non-null   float64\n",
            " 18  question_interestingness_self          6079 non-null   float64\n",
            " 19  question_multi_intent                  6079 non-null   float64\n",
            " 20  question_not_really_a_question         6079 non-null   float64\n",
            " 21  question_opinion_seeking               6079 non-null   float64\n",
            " 22  question_type_choice                   6079 non-null   float64\n",
            " 23  question_type_compare                  6079 non-null   float64\n",
            " 24  question_type_consequence              6079 non-null   float64\n",
            " 25  question_type_definition               6079 non-null   float64\n",
            " 26  question_type_entity                   6079 non-null   float64\n",
            " 27  question_type_instructions             6079 non-null   float64\n",
            " 28  question_type_procedure                6079 non-null   float64\n",
            " 29  question_type_reason_explanation       6079 non-null   float64\n",
            " 30  question_type_spelling                 6079 non-null   float64\n",
            " 31  question_well_written                  6079 non-null   float64\n",
            " 32  answer_helpful                         6079 non-null   float64\n",
            " 33  answer_level_of_information            6079 non-null   float64\n",
            " 34  answer_plausible                       6079 non-null   float64\n",
            " 35  answer_relevance                       6079 non-null   float64\n",
            " 36  answer_satisfaction                    6079 non-null   float64\n",
            " 37  answer_type_instructions               6079 non-null   float64\n",
            " 38  answer_type_procedure                  6079 non-null   float64\n",
            " 39  answer_type_reason_explanation         6079 non-null   float64\n",
            " 40  answer_well_written                    6079 non-null   float64\n",
            "dtypes: float64(30), int64(1), object(10)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ],
      "source": [
        "#View the structure\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192e4bb6",
      "metadata": {
        "id": "192e4bb6"
      },
      "outputs": [],
      "source": [
        "#Make a copy of the original training df\n",
        "df_train_1 = df_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f857377a",
      "metadata": {
        "id": "f857377a"
      },
      "outputs": [],
      "source": [
        "#A list of all the labels available for questions\n",
        "question_labels = [i for i in df_train.columns if i.startswith(\"question_\")]\n",
        "#There are 21 Labels and 4 Question related info like title, body and user info\n",
        "\n",
        "#A list of all the labels available for answers\n",
        "answer_labels = [i for i in df_train.columns if i.startswith(\"answer_\")]\n",
        "#There are 9 Labels and 2 Answer related info like user info  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47aa8acd",
      "metadata": {
        "id": "47aa8acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c052cb-23c2-4057-8f34-7dac79f467a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question_asker_intent_understanding\n",
            "0.00    0.333333\n",
            "0.25    0.777778\n",
            "0.50    0.888889\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_asker_intent_understanding, dtype: float64\n",
            "question_body_critical\n",
            "0.00    0.333333\n",
            "0.25    0.444444\n",
            "0.50    0.555556\n",
            "0.75    0.777778\n",
            "1.00    1.000000\n",
            "Name: question_body_critical, dtype: float64\n",
            "question_conversational\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_conversational, dtype: float64\n",
            "question_expect_short_answer\n",
            "0.00    0.000000\n",
            "0.25    0.500000\n",
            "0.50    0.666667\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_expect_short_answer, dtype: float64\n",
            "question_fact_seeking\n",
            "0.00    0.000000\n",
            "0.25    0.666667\n",
            "0.50    1.000000\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_fact_seeking, dtype: float64\n",
            "question_has_commonly_accepted_answer\n",
            "0.00    0.000000\n",
            "0.25    0.666667\n",
            "0.50    1.000000\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_has_commonly_accepted_answer, dtype: float64\n",
            "question_interestingness_others\n",
            "0.00    0.333333\n",
            "0.25    0.444444\n",
            "0.50    0.555556\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: question_interestingness_others, dtype: float64\n",
            "question_interestingness_self\n",
            "0.00    0.333333\n",
            "0.25    0.333333\n",
            "0.50    0.444444\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: question_interestingness_self, dtype: float64\n",
            "question_multi_intent\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.000000\n",
            "0.75    0.333333\n",
            "1.00    1.000000\n",
            "Name: question_multi_intent, dtype: float64\n",
            "question_not_really_a_question\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_not_really_a_question, dtype: float64\n",
            "question_opinion_seeking\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.333333\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: question_opinion_seeking, dtype: float64\n",
            "question_type_choice\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.000000\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: question_type_choice, dtype: float64\n",
            "question_type_compare\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_type_compare, dtype: float64\n",
            "question_type_consequence\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_type_consequence, dtype: float64\n",
            "question_type_definition\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_type_definition, dtype: float64\n",
            "question_type_entity\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.0\n",
            "0.75    0.0\n",
            "1.00    1.0\n",
            "Name: question_type_entity, dtype: float64\n",
            "question_type_instructions\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.666667\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_type_instructions, dtype: float64\n",
            "question_type_procedure\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.000000\n",
            "0.75    0.333333\n",
            "1.00    1.000000\n",
            "Name: question_type_procedure, dtype: float64\n",
            "question_type_reason_explanation\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.333333\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: question_type_reason_explanation, dtype: float64\n",
            "question_type_spelling\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.000000\n",
            "0.75    0.000000\n",
            "1.00    0.666667\n",
            "Name: question_type_spelling, dtype: float64\n",
            "question_well_written\n",
            "0.00    0.333333\n",
            "0.25    0.666667\n",
            "0.50    0.833333\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: question_well_written, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Question Labels are values that have a value between 0 to 1(Basically Probability).\n",
        "#Here we are trying to see what are the values for these labels at following 5 quantiles:\n",
        "#0%, 25%, 50%, 75% and 100%\n",
        "#We are taking question_labels from 4 as first 4 are not labels, they are the title, body and \n",
        "#user info related to question\n",
        "for i in question_labels[4:]:\n",
        "    #Print the label name\n",
        "    print(i)\n",
        "    #Print the quantile values\n",
        "    print(df_train[i].quantile([0,0.25,0.5,0.75,1]))\n",
        "#     df_train[i].hist()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2475658e",
      "metadata": {
        "id": "2475658e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2a4bbb-7f2f-4206-f413-e356305eac8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer_helpful\n",
            "0.00    0.333333\n",
            "0.25    0.888889\n",
            "0.50    1.000000\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: answer_helpful, dtype: float64\n",
            "answer_level_of_information\n",
            "0.00    0.333333\n",
            "0.25    0.666667\n",
            "0.50    0.666667\n",
            "0.75    0.666667\n",
            "1.00    1.000000\n",
            "Name: answer_level_of_information, dtype: float64\n",
            "answer_plausible\n",
            "0.00    0.333333\n",
            "0.25    1.000000\n",
            "0.50    1.000000\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: answer_plausible, dtype: float64\n",
            "answer_relevance\n",
            "0.00    0.333333\n",
            "0.25    1.000000\n",
            "0.50    1.000000\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: answer_relevance, dtype: float64\n",
            "answer_satisfaction\n",
            "0.00    0.200000\n",
            "0.25    0.800000\n",
            "0.50    0.866667\n",
            "0.75    0.933333\n",
            "1.00    1.000000\n",
            "Name: answer_satisfaction, dtype: float64\n",
            "answer_type_instructions\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.5\n",
            "0.75    1.0\n",
            "1.00    1.0\n",
            "Name: answer_type_instructions, dtype: float64\n",
            "answer_type_procedure\n",
            "0.00    0.000000\n",
            "0.25    0.000000\n",
            "0.50    0.000000\n",
            "0.75    0.333333\n",
            "1.00    1.000000\n",
            "Name: answer_type_procedure, dtype: float64\n",
            "answer_type_reason_explanation\n",
            "0.00    0.0\n",
            "0.25    0.0\n",
            "0.50    0.5\n",
            "0.75    1.0\n",
            "1.00    1.0\n",
            "Name: answer_type_reason_explanation, dtype: float64\n",
            "answer_well_written\n",
            "0.00    0.333333\n",
            "0.25    0.888889\n",
            "0.50    0.888889\n",
            "0.75    1.000000\n",
            "1.00    1.000000\n",
            "Name: answer_well_written, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Answer Labels are values that have a value between 0 to 1(Basically Probability).\n",
        "#Here we are trying to see what are the values for these labels at following 5 quantiles:\n",
        "#0%, 25%, 50%, 75% and 100%\n",
        "#We are taking answer_labels from 2 as first 2 are not labels, they are the answer and \n",
        "#user info related to answer\n",
        "for i in answer_labels[2:]:\n",
        "    #Print the answer label\n",
        "    print(i)\n",
        "    #print the quantile values\n",
        "    print(df_train[i].quantile([0,0.25,0.5,0.75,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "104159f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104159f1",
        "outputId": "f0c37b74-91de-4fa8-99b3-f83cb95119cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000000    6013\n",
              "0.333333      48\n",
              "0.500000      11\n",
              "0.666667       4\n",
              "1.000000       3\n",
              "Name: question_not_really_a_question, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "#Getting the Value Count for the Label to check if the labels are balanced\n",
        "df_train.question_not_really_a_question.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcff05d0",
      "metadata": {
        "id": "bcff05d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3546325e-3606-46b5-8c26-b9d061d0255d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question_asker_intent_understanding\n",
            "1.000000    2833\n",
            "0.888889    1579\n",
            "0.777778     883\n",
            "0.666667     503\n",
            "0.833333     108\n",
            "0.333333      68\n",
            "0.555556      60\n",
            "0.500000      33\n",
            "0.444444      12\n",
            "Name: question_asker_intent_understanding, dtype: int64\n",
            "question_body_critical\n",
            "0.333333    1506\n",
            "0.555556     932\n",
            "0.444444     893\n",
            "0.666667     845\n",
            "0.777778     701\n",
            "1.000000     583\n",
            "0.888889     470\n",
            "0.500000      94\n",
            "0.833333      55\n",
            "Name: question_body_critical, dtype: int64\n",
            "question_conversational\n",
            "0.000000    5409\n",
            "0.333333     384\n",
            "0.666667     152\n",
            "1.000000     104\n",
            "0.500000      30\n",
            "Name: question_conversational, dtype: int64\n",
            "question_expect_short_answer\n",
            "1.000000    2936\n",
            "0.666667    1373\n",
            "0.000000     806\n",
            "0.333333     522\n",
            "0.500000     442\n",
            "Name: question_expect_short_answer, dtype: int64\n",
            "question_fact_seeking\n",
            "1.000000    3480\n",
            "0.666667    1326\n",
            "0.333333     877\n",
            "0.000000     315\n",
            "0.500000      81\n",
            "Name: question_fact_seeking, dtype: int64\n",
            "question_has_commonly_accepted_answer\n",
            "1.000000    4071\n",
            "0.666667     794\n",
            "0.000000     657\n",
            "0.333333     324\n",
            "0.500000     233\n",
            "Name: question_has_commonly_accepted_answer, dtype: int64\n",
            "question_interestingness_others\n",
            "0.666667    1831\n",
            "0.555556    1699\n",
            "0.444444    1258\n",
            "0.777778     471\n",
            "0.333333     324\n",
            "0.500000     196\n",
            "0.888889     155\n",
            "1.000000     100\n",
            "0.833333      45\n",
            "Name: question_interestingness_others, dtype: int64\n",
            "question_interestingness_self\n",
            "0.333333    2124\n",
            "0.444444    1425\n",
            "0.555556     827\n",
            "0.666667     643\n",
            "0.777778     390\n",
            "1.000000     242\n",
            "0.888889     209\n",
            "0.500000     178\n",
            "0.833333      41\n",
            "Name: question_interestingness_self, dtype: int64\n",
            "question_multi_intent\n",
            "0.000000    3617\n",
            "0.333333    1094\n",
            "0.666667     697\n",
            "1.000000     573\n",
            "0.500000      98\n",
            "Name: question_multi_intent, dtype: int64\n",
            "question_not_really_a_question\n",
            "0.000000    6013\n",
            "0.333333      48\n",
            "0.500000      11\n",
            "0.666667       4\n",
            "1.000000       3\n",
            "Name: question_not_really_a_question, dtype: int64\n",
            "question_opinion_seeking\n",
            "0.000000    1964\n",
            "0.666667    1455\n",
            "0.333333    1399\n",
            "1.000000    1094\n",
            "0.500000     167\n",
            "Name: question_opinion_seeking, dtype: int64\n",
            "question_type_choice\n",
            "0.000000    3363\n",
            "0.333333    1064\n",
            "1.000000     875\n",
            "0.666667     683\n",
            "0.500000      94\n",
            "Name: question_type_choice, dtype: int64\n",
            "question_type_compare\n",
            "0.000000    5652\n",
            "0.333333     222\n",
            "0.666667     119\n",
            "1.000000      71\n",
            "0.500000      15\n",
            "Name: question_type_compare, dtype: int64\n",
            "question_type_consequence\n",
            "0.000000    5948\n",
            "0.333333      86\n",
            "0.666667      26\n",
            "1.000000      11\n",
            "0.500000       8\n",
            "Name: question_type_consequence, dtype: int64\n",
            "question_type_definition\n",
            "0.000000    5735\n",
            "0.333333     173\n",
            "0.666667     110\n",
            "1.000000      51\n",
            "0.500000      10\n",
            "Name: question_type_definition, dtype: int64\n",
            "question_type_entity\n",
            "0.000000    5348\n",
            "0.333333     391\n",
            "0.666667     172\n",
            "1.000000     135\n",
            "0.500000      33\n",
            "Name: question_type_entity, dtype: int64\n",
            "question_type_instructions\n",
            "0.000000    2171\n",
            "1.000000    1985\n",
            "0.666667    1122\n",
            "0.333333     652\n",
            "0.500000     149\n",
            "Name: question_type_instructions, dtype: int64\n",
            "question_type_procedure\n",
            "0.000000    3958\n",
            "0.333333    1313\n",
            "0.666667     533\n",
            "1.000000     158\n",
            "0.500000     117\n",
            "Name: question_type_procedure, dtype: int64\n",
            "question_type_reason_explanation\n",
            "0.000000    2456\n",
            "0.333333    1316\n",
            "1.000000    1171\n",
            "0.666667    1027\n",
            "0.500000     109\n",
            "Name: question_type_reason_explanation, dtype: int64\n",
            "question_type_spelling\n",
            "0.000000    6068\n",
            "0.333333       7\n",
            "0.666667       4\n",
            "Name: question_type_spelling, dtype: int64\n",
            "question_well_written\n",
            "1.000000    1619\n",
            "0.888889    1337\n",
            "0.777778    1111\n",
            "0.666667     839\n",
            "0.555556     539\n",
            "0.444444     307\n",
            "0.833333     163\n",
            "0.333333     131\n",
            "0.500000      33\n",
            "Name: question_well_written, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Getting the Value Count for the question_label to check if the labels are balanced\n",
        "#before modifications\n",
        "for i in question_labels[4:]:\n",
        "    #Print the label name\n",
        "    print(i)\n",
        "    #Print the value counts\n",
        "    print(df_train[i].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58f046b2",
      "metadata": {
        "id": "58f046b2"
      },
      "source": [
        "**Initially we are trying to set a threshold of 0.5 and label the questions based on the major label values that we find in the question_labels. To do this we need to have 0 or 1 label values instead of values between 0 to 1.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2991e466",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2991e466",
        "outputId": "78045d4d-a646-4d84-f937-73728e65bf6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-100-82983c7102ba>:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  df_train.iloc[:, 11:] = df_train.iloc[:, 11:].apply(lambda x: pd.Series([1 if val >= 0.5 else 0 for val in x]))\n"
          ]
        }
      ],
      "source": [
        "#Get the labels with either 0 or 1 values instead of a value in the range 0-1\n",
        "df_train.iloc[:, 11:] = df_train.iloc[:, 11:].apply(lambda x: pd.Series([1 if val >= 0.5 else 0 for val in x]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the first 6 records\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioNbBNja8-3X",
        "outputId": "1154f174-27fc-442f-b68e-0280343ea561"
      },
      "id": "ioNbBNja8-3X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qa_id                                     question_title  \\\n",
              "0      0  What am I losing when using extension tubes in...   \n",
              "1      1  What is the distinction between a city and a s...   \n",
              "2      2  Maximum protusion length for through-hole comp...   \n",
              "3      3              Can an affidavit be used in Beit Din?   \n",
              "4      5       How do you make a binary image in Photoshop?   \n",
              "\n",
              "                                       question_body question_user_name  \\\n",
              "0  After playing around with macro photography on...               ysap   \n",
              "1  I am trying to understand what kinds of places...      russellpierce   \n",
              "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
              "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
              "4  I am trying to make a binary image. I want mor...            leigero   \n",
              "\n",
              "                                  question_user_page  \\\n",
              "0         https://photo.stackexchange.com/users/1024   \n",
              "1           https://rpg.stackexchange.com/users/8774   \n",
              "2  https://electronics.stackexchange.com/users/10157   \n",
              "3       https://judaism.stackexchange.com/users/5151   \n",
              "4  https://graphicdesign.stackexchange.com/users/...   \n",
              "\n",
              "                                              answer answer_user_name  \\\n",
              "0  I just got extension tubes, so here's the skin...           rfusca   \n",
              "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
              "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
              "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
              "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
              "\n",
              "                                    answer_user_page  \\\n",
              "0         https://photo.stackexchange.com/users/1917   \n",
              "1           https://rpg.stackexchange.com/users/1871   \n",
              "2  https://electronics.stackexchange.com/users/64754   \n",
              "3       https://judaism.stackexchange.com/users/4794   \n",
              "4  https://graphicdesign.stackexchange.com/users/...   \n",
              "\n",
              "                                                 url   category  ...  \\\n",
              "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
              "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
              "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
              "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
              "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
              "\n",
              "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
              "0                     1               1                            1   \n",
              "1                     1               1                            1   \n",
              "2                     1               1                            1   \n",
              "3                     1               1                            0   \n",
              "4                     1               1                            1   \n",
              "\n",
              "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
              "0                 1                 1                    1   \n",
              "1                 1                 1                    1   \n",
              "2                 1                 1                    1   \n",
              "3                 1                 1                    1   \n",
              "4                 1                 1                    1   \n",
              "\n",
              "   answer_type_instructions  answer_type_procedure  \\\n",
              "0                         1                      0   \n",
              "1                         0                      0   \n",
              "2                         0                      0   \n",
              "3                         0                      0   \n",
              "4                         1                      0   \n",
              "\n",
              "   answer_type_reason_explanation  answer_well_written  \n",
              "0                               0                    1  \n",
              "1                               1                    1  \n",
              "2                               1                    1  \n",
              "3                               1                    1  \n",
              "4                               1                    1  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0922be17-7424-403f-b544-f42c6e4a5a2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_id</th>\n",
              "      <th>question_title</th>\n",
              "      <th>question_body</th>\n",
              "      <th>question_user_name</th>\n",
              "      <th>question_user_page</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_user_name</th>\n",
              "      <th>answer_user_page</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>...</th>\n",
              "      <th>question_well_written</th>\n",
              "      <th>answer_helpful</th>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <th>answer_plausible</th>\n",
              "      <th>answer_relevance</th>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <th>answer_well_written</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What am I losing when using extension tubes in...</td>\n",
              "      <td>After playing around with macro photography on...</td>\n",
              "      <td>ysap</td>\n",
              "      <td>https://photo.stackexchange.com/users/1024</td>\n",
              "      <td>I just got extension tubes, so here's the skin...</td>\n",
              "      <td>rfusca</td>\n",
              "      <td>https://photo.stackexchange.com/users/1917</td>\n",
              "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the distinction between a city and a s...</td>\n",
              "      <td>I am trying to understand what kinds of places...</td>\n",
              "      <td>russellpierce</td>\n",
              "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
              "      <td>It might be helpful to look into the definitio...</td>\n",
              "      <td>Erik Schmidt</td>\n",
              "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
              "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Maximum protusion length for through-hole comp...</td>\n",
              "      <td>I'm working on a PCB that has through-hole com...</td>\n",
              "      <td>Joe Baker</td>\n",
              "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
              "      <td>Do you even need grooves?  We make several pro...</td>\n",
              "      <td>Dwayne Reid</td>\n",
              "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
              "      <td>http://electronics.stackexchange.com/questions...</td>\n",
              "      <td>SCIENCE</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Can an affidavit be used in Beit Din?</td>\n",
              "      <td>An affidavit, from what i understand, is basic...</td>\n",
              "      <td>Scimonster</td>\n",
              "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
              "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
              "      <td>Y     e     z</td>\n",
              "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
              "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
              "      <td>CULTURE</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>How do you make a binary image in Photoshop?</td>\n",
              "      <td>I am trying to make a binary image. I want mor...</td>\n",
              "      <td>leigero</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
              "      <td>q2ra</td>\n",
              "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
              "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
              "      <td>LIFE_ARTS</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0922be17-7424-403f-b544-f42c6e4a5a2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0922be17-7424-403f-b544-f42c6e4a5a2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0922be17-7424-403f-b544-f42c6e4a5a2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393f9c49",
      "metadata": {
        "id": "393f9c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2182b1e5-316c-4080-a457-4b96ec1ba1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question_asker_intent_understanding\n",
            "1    0.98684\n",
            "0    0.01316\n",
            "Name: question_asker_intent_understanding, dtype: float64\n",
            "1    5999\n",
            "0      80\n",
            "Name: question_asker_intent_understanding, dtype: int64\n",
            "question_body_critical\n",
            "1    0.605363\n",
            "0    0.394637\n",
            "Name: question_body_critical, dtype: float64\n",
            "1    3680\n",
            "0    2399\n",
            "Name: question_body_critical, dtype: int64\n",
            "question_conversational\n",
            "0    0.952953\n",
            "1    0.047047\n",
            "Name: question_conversational, dtype: float64\n",
            "0    5793\n",
            "1     286\n",
            "Name: question_conversational, dtype: int64\n",
            "question_expect_short_answer\n",
            "1    0.781543\n",
            "0    0.218457\n",
            "Name: question_expect_short_answer, dtype: float64\n",
            "1    4751\n",
            "0    1328\n",
            "Name: question_expect_short_answer, dtype: int64\n",
            "question_fact_seeking\n",
            "1    0.803915\n",
            "0    0.196085\n",
            "Name: question_fact_seeking, dtype: float64\n",
            "1    4887\n",
            "0    1192\n",
            "Name: question_fact_seeking, dtype: int64\n",
            "question_has_commonly_accepted_answer\n",
            "1    0.838625\n",
            "0    0.161375\n",
            "Name: question_has_commonly_accepted_answer, dtype: float64\n",
            "1    5098\n",
            "0     981\n",
            "Name: question_has_commonly_accepted_answer, dtype: int64\n",
            "question_interestingness_others\n",
            "1    0.73976\n",
            "0    0.26024\n",
            "Name: question_interestingness_others, dtype: float64\n",
            "1    4497\n",
            "0    1582\n",
            "Name: question_interestingness_others, dtype: int64\n",
            "question_interestingness_self\n",
            "0    0.583813\n",
            "1    0.416187\n",
            "Name: question_interestingness_self, dtype: float64\n",
            "0    3549\n",
            "1    2530\n",
            "Name: question_interestingness_self, dtype: int64\n",
            "question_multi_intent\n",
            "0    0.774963\n",
            "1    0.225037\n",
            "Name: question_multi_intent, dtype: float64\n",
            "0    4711\n",
            "1    1368\n",
            "Name: question_multi_intent, dtype: int64\n",
            "question_not_really_a_question\n",
            "0    0.997039\n",
            "1    0.002961\n",
            "Name: question_not_really_a_question, dtype: float64\n",
            "0    6061\n",
            "1      18\n",
            "Name: question_not_really_a_question, dtype: int64\n",
            "question_opinion_seeking\n",
            "0    0.553216\n",
            "1    0.446784\n",
            "Name: question_opinion_seeking, dtype: float64\n",
            "0    3363\n",
            "1    2716\n",
            "Name: question_opinion_seeking, dtype: int64\n",
            "question_type_choice\n",
            "0    0.728245\n",
            "1    0.271755\n",
            "Name: question_type_choice, dtype: float64\n",
            "0    4427\n",
            "1    1652\n",
            "Name: question_type_choice, dtype: int64\n",
            "question_type_compare\n",
            "0    0.966277\n",
            "1    0.033723\n",
            "Name: question_type_compare, dtype: float64\n",
            "0    5874\n",
            "1     205\n",
            "Name: question_type_compare, dtype: int64\n",
            "question_type_consequence\n",
            "0    0.992597\n",
            "1    0.007403\n",
            "Name: question_type_consequence, dtype: float64\n",
            "0    6034\n",
            "1      45\n",
            "Name: question_type_consequence, dtype: int64\n",
            "question_type_definition\n",
            "0    0.97187\n",
            "1    0.02813\n",
            "Name: question_type_definition, dtype: float64\n",
            "0    5908\n",
            "1     171\n",
            "Name: question_type_definition, dtype: int64\n",
            "question_type_entity\n",
            "0    0.94407\n",
            "1    0.05593\n",
            "Name: question_type_entity, dtype: float64\n",
            "0    5739\n",
            "1     340\n",
            "Name: question_type_entity, dtype: int64\n",
            "question_type_instructions\n",
            "1    0.535614\n",
            "0    0.464386\n",
            "Name: question_type_instructions, dtype: float64\n",
            "1    3256\n",
            "0    2823\n",
            "Name: question_type_instructions, dtype: int64\n",
            "question_type_procedure\n",
            "0    0.867083\n",
            "1    0.132917\n",
            "Name: question_type_procedure, dtype: float64\n",
            "0    5271\n",
            "1     808\n",
            "Name: question_type_procedure, dtype: int64\n",
            "question_type_reason_explanation\n",
            "0    0.620497\n",
            "1    0.379503\n",
            "Name: question_type_reason_explanation, dtype: float64\n",
            "0    3772\n",
            "1    2307\n",
            "Name: question_type_reason_explanation, dtype: int64\n",
            "question_type_spelling\n",
            "0    0.999342\n",
            "1    0.000658\n",
            "Name: question_type_spelling, dtype: float64\n",
            "0    6075\n",
            "1       4\n",
            "Name: question_type_spelling, dtype: int64\n",
            "question_well_written\n",
            "1    0.927949\n",
            "0    0.072051\n",
            "Name: question_well_written, dtype: float64\n",
            "1    5641\n",
            "0     438\n",
            "Name: question_well_written, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Getting the Value Count in absolute and percentage for the question_label to\n",
        "#check if the labels are balanced after modifications\n",
        "for i in question_labels[4:]:\n",
        "    #Print the label name\n",
        "    print(i)\n",
        "    #Print the value counts in percentage\n",
        "    print(df_train[i].value_counts(normalize=True))\n",
        "    print(df_train[i].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce487b65",
      "metadata": {
        "id": "ce487b65"
      },
      "source": [
        "**The Labels are imbalanced based on the analysis of the data that we conducted. Therefore, we need a way to balance the labels so that the model does not become bias on the majority class. Based on the analysis and taking 85% for majority class and 15% for minority class as the distribution, we need to perform oversampling on the labels where the imbalance crosses this threshold.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OVERSAMPLER & FUNCTIONS"
      ],
      "metadata": {
        "id": "S7se8khhLtIQ"
      },
      "id": "S7se8khhLtIQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aa5fa64",
      "metadata": {
        "id": "7aa5fa64"
      },
      "outputs": [],
      "source": [
        "### This is something we tried to see how the Oversampling works on one of the labels\n",
        "\n",
        "# # define the oversampling ratio\n",
        "# oversample_ratio = 0.05/0.95  # desired ratio of majority class to minority class\n",
        "\n",
        "# # create the oversampler object\n",
        "# oversampler = RandomOverSampler(sampling_strategy=oversample_ratio, random_state=0)\n",
        "\n",
        "# # fit and apply the oversampler to the data\n",
        "# X_resampled, y_resampled = oversampler.fit_resample(df_train.drop(\"question_asker_intent_understanding\", axis=1), df_train['question_asker_intent_understanding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c111e3b",
      "metadata": {
        "id": "4c111e3b"
      },
      "outputs": [],
      "source": [
        "#Create a function to perform Random Oversampling\n",
        "#It take 3 inputs: dataframe, column on which to run and a oversample ratio\n",
        "#Taking Oversampling ratio of 15% isto 85% i.e., \n",
        "#minority class: 15% and majority class: 85%\n",
        "def df_oversampler(df, col, oversample_ratio = 0.15/0.85):\n",
        "  #Initialize an instance of Random Smapler\n",
        "  oversampler = RandomOverSampler(sampling_strategy=oversample_ratio, random_state=0)\n",
        "  #Fit the data to the Random Sampler\n",
        "  X_resampled, y_resampled = oversampler.fit_resample(df_train.drop(col, axis=1), df_train[col])\n",
        "  #Return the processed data\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to perform Random Oversampling\n",
        "#It take 3 inputs: dataframe, column on which to run and a oversample ratio\n",
        "#Taking Oversampling ratio of 15% isto 85% i.e., \n",
        "#minority class: 15% and majority class: 85%\n",
        "def array_oversampler(array_x, array_y, oversample_ratio = 0.15/0.85):\n",
        "  #Initialize an instance of Random Smapler\n",
        "  oversampler = RandomOverSampler(sampling_strategy=oversample_ratio, random_state=0)\n",
        "  #Fit the data to the Random Sampler\n",
        "  X_resampled, y_resampled = oversampler.fit_resample(array_x, array_y)\n",
        "  #Return the processed data\n",
        "  return X_resampled, y_resampled"
      ],
      "metadata": {
        "id": "mC3mTd5Aw8lo"
      },
      "id": "mC3mTd5Aw8lo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the function\n",
        "X_resampled, y_resampled = df_oversampler(df_train, \"question_asker_intent_understanding\")"
      ],
      "metadata": {
        "id": "TArSwNWD-GYI"
      },
      "id": "TArSwNWD-GYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL MAX SENTENCE LENGTH EDA"
      ],
      "metadata": {
        "id": "zKEh6awJL1BW"
      },
      "id": "zKEh6awJL1BW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b95728",
      "metadata": {
        "id": "23b95728",
        "outputId": "96864762-ee9a-420f-aaaf-8089bfee97c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX: 1416 \n",
            "MEDIAN: 92\n",
            "MEAN: 125.2636946866261\n",
            "75th Percentile: 154.0\n",
            "These are the results before any data-preprocessing on the question_body\n"
          ]
        }
      ],
      "source": [
        "#We are trying to determine what should be the allowed maximum length of a sentence\n",
        "\n",
        "#Create a empty list\n",
        "length_question_body = []\n",
        "\n",
        "#Iterate the reviewText and make a list of sentences\n",
        "for sen in df_train[\"question_body\"]:\n",
        "  length = len(sen.split())\n",
        "  length_question_body.append(length)\n",
        "\n",
        "#Plot a histogram to show the length of each sentence\n",
        "plt.hist(length_question_body)\n",
        "plt.show()\n",
        "\n",
        "#Print the descriptive statistics\n",
        "print(\"MAX: {} \".format(max(length_question_body)))\n",
        "print(\"MEDIAN: {}\".format(statistics.median(length_question_body)))\n",
        "print(\"MEAN: {}\".format(statistics.mean(length_question_body)))\n",
        "print(\"75th Percentile: {}\".format(np.percentile(length_question_body, 75)))\n",
        "print(\"These are the results before any data-preprocessing on the question_body\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0619a52",
      "metadata": {
        "id": "f0619a52",
        "outputId": "9c232228-ad3e-4621-afc6-505b915d1224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX: 28 \n",
            "MEDIAN: 9\n",
            "MEAN: 9.034874156933705\n",
            "75th Percentile: 11.0\n",
            "These are the results before any data-preprocessing on the question_title\n"
          ]
        }
      ],
      "source": [
        "#We are trying to determine what should be the allowed maximum length of title\n",
        "\n",
        "#Create a empty list\n",
        "length_question_title = []\n",
        "\n",
        "#Iterate the reviewText and make a list of sentences\n",
        "for sen in df_train[\"question_title\"]:\n",
        "  length = len(sen.split())\n",
        "  length_question_title.append(length)\n",
        "\n",
        "#Plot a histogram to show the length of each sentence\n",
        "plt.hist(length_question_title)\n",
        "plt.show()\n",
        "\n",
        "#Print the descriptive statistics\n",
        "print(\"MAX: {} \".format(max(length_question_title)))\n",
        "print(\"MEDIAN: {}\".format(statistics.median(length_question_title)))\n",
        "print(\"MEAN: {}\".format(statistics.mean(length_question_title)))\n",
        "print(\"75th Percentile: {}\".format(np.percentile(length_question_title, 75)))\n",
        "print(\"These are the results before any data-preprocessing on the question_title\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3206b8db",
      "metadata": {
        "id": "3206b8db",
        "outputId": "9acbca59-d4ad-4798-ab96-e691286b9a64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX: 1 \n",
            "MEDIAN: 1\n",
            "MEAN: 1\n",
            "These are the results before any data-preprocessing on the category\n"
          ]
        }
      ],
      "source": [
        "#We are trying to determine what should be the allowed maximum length of category\n",
        "\n",
        "#Create a empty list\n",
        "length_category = []\n",
        "\n",
        "#Iterate the reviewText and make a list of sentences\n",
        "for sen in df_train[\"category\"]:\n",
        "  length = len(sen.split())\n",
        "  length_category.append(length)\n",
        "\n",
        "#Plot a histogram to show the length of each sentence\n",
        "plt.hist(length_category)\n",
        "plt.show()\n",
        "\n",
        "#Print the descriptive statistics\n",
        "print(\"MAX: {} \".format(max(length_category)))\n",
        "print(\"MEDIAN: {}\".format(statistics.median(length_category)))\n",
        "print(\"MEAN: {}\".format(statistics.mean(length_category)))\n",
        "print(\"These are the results before any data-preprocessing on the category\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We are trying to determine what should be the allowed maximum length of category\n",
        "\n",
        "#Create a empty list\n",
        "length_answer = []\n",
        "\n",
        "#Iterate the reviewText and make a list of sentences\n",
        "for sen in df_train[\"answer\"]:\n",
        "  length = len(sen.split())\n",
        "  length_answer.append(length)\n",
        "\n",
        "#Plot a histogram to show the length of each sentence\n",
        "plt.hist(length_answer)\n",
        "plt.show()\n",
        "\n",
        "#Print the descriptive statistics\n",
        "print(\"MAX: {} \".format(max(length_answer)))\n",
        "print(\"MEDIAN: {}\".format(statistics.median(length_answer)))\n",
        "print(\"MEAN: {}\".format(statistics.mean(length_answer)))\n",
        "print(\"These are the results before any data-preprocessing on the answer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiJ2vJ7BB2Gh",
        "outputId": "711fe779-b19a-498f-c93e-d43d2d7a82b7"
      },
      "id": "GiJ2vJ7BB2Gh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAX: 2376 \n",
            "MEDIAN: 88\n",
            "MEAN: 133.0222075999342\n",
            "These are the results before any data-preprocessing on the answer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e61368d",
      "metadata": {
        "id": "1e61368d"
      },
      "source": [
        "**Based on the histogram and descriptive statistics of category, question_title and question_body, we determine that the maximum allowed length (max_length) for the 3 attributes are as follows:(Taking 1.5x as factor on 75th Percentile)<br>\n",
        "category: 1 (Based on the Histogram)<br>\n",
        "question_title: 1.5x 11 = 16.5<br>\n",
        "question_body: 1.5x 154 = 231<br>\n",
        "answer: 1.5x 133 = 200<br>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL BUILDING"
      ],
      "metadata": {
        "id": "ITAif9l7L_lM"
      },
      "id": "ITAif9l7L_lM"
    },
    {
      "cell_type": "code",
      "source": [
        "#Makeing a list of all the label columns\n",
        "cols = ['question_asker_intent_understanding',\n",
        "       'question_body_critical', 'question_conversational',\n",
        "       'question_expect_short_answer', 'question_fact_seeking',\n",
        "       'question_has_commonly_accepted_answer',\n",
        "       'question_interestingness_others', 'question_interestingness_self',\n",
        "       'question_multi_intent', 'question_not_really_a_question',\n",
        "       'question_opinion_seeking', 'question_type_choice',\n",
        "       'question_type_compare', 'question_type_consequence',\n",
        "       'question_type_definition', 'question_type_entity',\n",
        "       'question_type_instructions', 'question_type_procedure',\n",
        "       'question_type_reason_explanation', 'question_type_spelling',\n",
        "       'question_well_written', 'answer_helpful',\n",
        "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
        "       'answer_satisfaction', 'answer_type_instructions',\n",
        "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
        "       'answer_well_written']"
      ],
      "metadata": {
        "id": "uNMvQFoDICEC"
      },
      "id": "uNMvQFoDICEC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the length to make sure it is 30\n",
        "len(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I1-GBRcIKri",
        "outputId": "3750baab-b24b-49ad-f92c-8279ba4c2fbb"
      },
      "id": "_I1-GBRcIKri",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 2 types of prediction model that we will build; one is with just questions & the other is question-answer pair.<br>  \n",
        "question_title, question_body, category > question_ labels [for Questions Only Model]<br>\n",
        "question_title, question_body, answer, category > answer_ labels [for Question-Ansewer Pair Model]**"
      ],
      "metadata": {
        "id": "nVkYG0AMj6lU"
      },
      "id": "nVkYG0AMj6lU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fdec951",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fdec951",
        "outputId": "1639d12b-d80b-40d6-8bf6-cd70bb6a4e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "#Based on the analysis of max length above defining the max length values\n",
        "#Here qt: question_title, qb: question_body and a: answer\n",
        "MODEL_MAX_LENGTH_qt = 16 \n",
        "MODEL_MAX_LENGTH_qb = 232\n",
        "MODEL_MAX_LENGTH_a = 200\n",
        "\n",
        "#Initilize the bert tokenizers for training the bert model\n",
        "bert_tokenizer_category = AutoTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          model_max_length = 5,\n",
        "                                          padding_side = \"right\",\n",
        "                                          truncation_side = \"right\")\n",
        "\n",
        "bert_tokenizer_qt = AutoTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          model_max_length = MODEL_MAX_LENGTH_qt,\n",
        "                                          padding_side = \"right\",\n",
        "                                          truncation_side = \"right\")\n",
        "bert_tokenizer_qb = AutoTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          model_max_length = MODEL_MAX_LENGTH_qb,\n",
        "                                          padding_side = \"right\",\n",
        "                                          truncation_side = \"right\")\n",
        "bert_tokenizer_a = AutoTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          model_max_length = MODEL_MAX_LENGTH_a,\n",
        "                                          padding_side = \"right\",\n",
        "                                          truncation_side = \"right\")\n",
        "\n",
        "#Initilize the bert model\n",
        "bert_model = AutoModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if we have GPU available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Acqqyh-wpmg-"
      },
      "id": "Acqqyh-wpmg-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Send the bert_model to the GPU\n",
        "bert_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRmeCLhjpjKV",
        "outputId": "26adb74c-0238-41e0-c0d4-3c7ae2a258eb"
      },
      "id": "JRmeCLhjpjKV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810c9f22",
      "metadata": {
        "id": "810c9f22"
      },
      "outputs": [],
      "source": [
        "# Checking to see what should be the right max length for category\n",
        "# bert_model.eval()\n",
        "# with torch.no_grad():\n",
        "#   x = bert_model(**bert_tokenizer_category('INSECT', padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True))['pooler_output'].numpy()\n",
        "# x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATASET AND DATALOADER DEFINITION"
      ],
      "metadata": {
        "id": "XVq1QEhfMHGW"
      },
      "id": "XVq1QEhfMHGW"
    },
    {
      "cell_type": "code",
      "source": [
        "#We are defining a custom collate function\n",
        "def custom_collate(data):\n",
        "    #Get the tockenizers from the collate_fn argument of the Dataloader \n",
        "    bert_tokenizer_qt = data[0][4]\n",
        "    bert_tokenizer_qb = data[0][5]\n",
        "    bert_tokenizer_a = data[0][6]\n",
        "    bert_tokenizer_category = data[0][7]\n",
        "    #Get the training data from the collate_fn argument of the Dataloader\n",
        "    X_qt = [i[0] for i in data]\n",
        "    X_qb = [i[1] for i in data]\n",
        "    X_a = [i[2] for i in data]\n",
        "    X_c = [i[3] for i in data]\n",
        "    #The try-except block returns batches of tokenized data\n",
        "    try:\n",
        "        Y = [i[8] for i in data]\n",
        "        return bert_tokenizer_qt(X_qt, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True), bert_tokenizer_qb(X_qb, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True),  bert_tokenizer_a(X_a, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True),  bert_tokenizer_category(X_c, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True), Y\n",
        "    except:\n",
        "        return bert_tokenizer_qt(X_qt, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True), bert_tokenizer_qb(X_qb, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True),  bert_tokenizer_a(X_a, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True),  bert_tokenizer_category(X_c, padding='max_length', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True)"
      ],
      "metadata": {
        "id": "shNhZnE5GHKX"
      },
      "id": "shNhZnE5GHKX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a class for the dataloader to handel the tokenization\n",
        "class QA_B_dataset(Dataset):\n",
        "  #initilize the tokenizers, dataframe training attributes and a boolean to check\n",
        "  #if the dataset input is for testing or training purpose\n",
        "  def __init__(self, df, cols, bert_tokenizer_qt, bert_tokenizer_qb, bert_tokenizer_a, bert_tokenizer_category, is_test=False, **kwargs):\n",
        "    super().__init__()\n",
        "    self.bert_tokenizer_qt = bert_tokenizer_qt\n",
        "    self.bert_tokenizer_qb = bert_tokenizer_qb\n",
        "    self.bert_tokenizer_a = bert_tokenizer_a\n",
        "    self.bert_tokenizer_category = bert_tokenizer_category\n",
        "    self.X_qt = df['question_title']\n",
        "    self.X_qb = df['question_body']\n",
        "    self.X_a = df['answer']\n",
        "    self.X_c = df['category']\n",
        "    self.is_test=is_test\n",
        "    if not self.is_test:\n",
        "        self.Y = df[cols]\n",
        "  \n",
        "  #Gives the shape of the   \n",
        "  def __len__(self):\n",
        "    return self.X_qt.shape[0]\n",
        "\n",
        "  #Based on if the dataset is training or testing we tokenize using the bert_tokenizer\n",
        "  #from out custom_collate function\n",
        "  def __getitem__(self, idx):\n",
        "    # x_encoded = self.tokenizer(self.X[idx], padding='longest', truncation='longest_first', return_tensors='pt', return_attention_mask=True, return_token_type_ids=True)\n",
        "    if not self.is_test:\n",
        "        return self.X_qt.iloc[idx], self.X_qb.iloc[idx], self.X_a.iloc[idx], self.X_c.iloc[idx], bert_tokenizer_qt, bert_tokenizer_qb, bert_tokenizer_a, bert_tokenizer_category, self.Y.iloc[idx].values\n",
        "    else:\n",
        "        return self.X_qt.iloc[idx], self.X_qb.iloc[idx], self.X_a.iloc[idx], self.X_c.iloc[idx], bert_tokenizer_qt, bert_tokenizer_qb, bert_tokenizer_a, bert_tokenizer_category"
      ],
      "metadata": {
        "id": "FI96YfQkC3iD"
      },
      "id": "FI96YfQkC3iD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the batch size\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "EJtp5sK6IWNt"
      },
      "id": "EJtp5sK6IWNt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initilize the dataloader class with all the required arguments\n",
        "dataloader_train = DataLoader(QA_B_dataset(df_train, cols, bert_tokenizer_qt, bert_tokenizer_qb, bert_tokenizer_a, bert_tokenizer_category), batch_size=BATCH_SIZE, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "FL__q2ufEIWn"
      },
      "id": "FL__q2ufEIWn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch index - the variable\n",
        "# 0 - qt\n",
        "# 1 - qb\n",
        "# 2 - a\n",
        "# 3 - c\n",
        "bert_model.eval()\n",
        "\n",
        "#Create empty lists to store the batches\n",
        "X_qt = []\n",
        "X_qb = []\n",
        "X_a = []\n",
        "X_c = []\n",
        "Y = []\n",
        "\n",
        "#Iterate through the dataloader\n",
        "for batch in tqdm(dataloader_train):\n",
        "    with torch.no_grad():\n",
        "      output_type = 'pooler_output' # last_hidden_state or pooler_output\n",
        "      #training the batched data using bert_model\n",
        "      out_qt = bert_model(**batch[0].to(device))[output_type].cpu().numpy()\n",
        "      out_qb = bert_model(**batch[1].to(device))[output_type].cpu().numpy()\n",
        "      out_a = bert_model(**batch[2].to(device))[output_type].cpu().numpy()\n",
        "      out_c = bert_model(**batch[3].to(device))[output_type].cpu().numpy()\n",
        "    #Stacking the batched labels \n",
        "    out_y = np.stack(batch[4])\n",
        "    #Appending the trained model to the lists that we created\n",
        "    X_qt.append(out_qt)\n",
        "    X_qb.append(out_qb)\n",
        "    X_a.append(out_a)\n",
        "    X_c.append(out_c)\n",
        "    Y.append(out_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a5005e4732fe444fab84551e7a114824",
            "e7ece6c2be254d47a51e842bd6fd0b4c",
            "ed0380158a1b4f3b993776b0989f6fec",
            "188292fae57e40b39bd3e8faa9fa07e9",
            "b9d489cfc5f24b0882195f618082b4d8",
            "9287103ca82f4f7fbd77b8d1e44bac43",
            "48099e182768436d89727239ce8f3e88",
            "82b1c841bb7f4d3ca7336a6558726e6e",
            "8c832da7003a4590ac39f5ab2df182d8",
            "86d3849bbf574d398d91ace3689d8fa3",
            "4e99b019339145f6a413eed225d14dac"
          ]
        },
        "id": "hMaYBICBIP9Q",
        "outputId": "b7754f9a-2952-4f55-b0fd-6baf96d84f87"
      },
      "id": "hMaYBICBIP9Q",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5005e4732fe444fab84551e7a114824",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/95 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenate the processed data and reshape such that we define the dimentions(768)\n",
        "#and sentence(1), th-1 is for model to figureout\n",
        "X_qt = np.concatenate(X_qt).reshape(-1,1,768)\n",
        "X_qb = np.concatenate(X_qb).reshape(-1,1,768)\n",
        "X_a = np.concatenate(X_a).reshape(-1,1,768)\n",
        "X_c = np.concatenate(X_c).reshape(-1,1,768)\n",
        "Y = np.concatenate(Y)"
      ],
      "metadata": {
        "id": "xBZPVmberDiY"
      },
      "id": "xBZPVmberDiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for questions only\n",
        "X_questions = np.concatenate([X_c, X_qt, X_qb], axis = 1)\n",
        "\n",
        "# for question answer pair\n",
        "X_answers = np.concatenate([X_c, X_qt, X_qb, X_a], axis = 1)"
      ],
      "metadata": {
        "id": "10-yY38fuNJ6"
      },
      "id": "10-yY38fuNJ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ONE COLUMN POC MODEL"
      ],
      "metadata": {
        "id": "29h-fDZ6MRuE"
      },
      "id": "29h-fDZ6MRuE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating a model on just one column to test if everything is running properly<br>\n",
        "question_asker_intent_understanding**  "
      ],
      "metadata": {
        "id": "kp1t99E44Rku"
      },
      "id": "kp1t99E44Rku"
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Column to be trained\n",
        "column_for_model = \"question_asker_intent_understanding\""
      ],
      "metadata": {
        "id": "3pfojDITvwLP"
      },
      "id": "3pfojDITvwLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define total number of rows\n",
        "total_rows = X_questions.shape[0]"
      ],
      "metadata": {
        "id": "UW7n5s_Ny4JC"
      },
      "id": "UW7n5s_Ny4JC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the model according to the condition if it is a question label or answer label\n",
        "X_model = X_questions if column_for_model.startswith(\"question_\") else X_answers\n",
        "#Define the max length based on if it is question only model or question-answer piar model\n",
        "MODEL_MAX_LENGTH = 3 if column_for_model.startswith(\"question_\") else 4\n",
        "#Check if the data is balanced amd according implement oversampling method\n",
        "if df_train[column_for_model].value_counts(normalize = True).iloc[0] > 0.85:\n",
        "    X_resampled, y_resampled = array_oversampler(X_model.reshape(total_rows, -1), Y[:,cols.index(column_for_model)])\n",
        "else:\n",
        "    X_resampled, y_resampled = X_model, Y[:,cols.index(column_for_model)]"
      ],
      "metadata": {
        "id": "lRhrEKs4v4W_"
      },
      "id": "lRhrEKs4v4W_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape the data to required shape and attributes for both training data and labels\n",
        "X_resampled = X_resampled.reshape(-1, MODEL_MAX_LENGTH, 768)\n",
        "y_resampled = pd.get_dummies(y_resampled).values"
      ],
      "metadata": {
        "id": "7g0Jhs0_zLow"
      },
      "id": "7g0Jhs0_zLow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Train-Test Sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled,y_resampled, test_size = 0.25, random_state = 42)"
      ],
      "metadata": {
        "id": "iSU7N88Pvipr"
      },
      "id": "iSU7N88Pvipr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_out = 64 \n",
        "# embid_dim = embedding_width # This needs to match the width of our gloVe vectors\n",
        "\n",
        "#Initilize the model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# The big difference here is that the embedding values are set to not trainable\n",
        "# model.add(Embedding(vocab_size, embid_dim, input_length =X.shape[1], weights = [embedding_matrix] , trainable = False))\n",
        "model.add(Bidirectional(LSTM(lstm_out, dropout=0.2), input_shape=(MODEL_MAX_LENGTH,768)))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMtYluntvUoD",
        "outputId": "63cd1529-7930-4200-912c-48c00c9d5e8f"
      },
      "id": "RMtYluntvUoD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_31 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the model batch size\n",
        "batch_size = 64\n",
        "#Compile the model with appropriate arguments\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "##Fit the model to get training and validation accuracy\n",
        "history = model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 1, validation_data =(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AArgNNXv0gUl",
        "outputId": "2216dd58-7db2-483a-bf7e-ac6e38b887f7"
      },
      "id": "AArgNNXv0gUl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FUNCTION FOR MODEL FOR COLUMN"
      ],
      "metadata": {
        "id": "ZpDVlhn2Mc0b"
      },
      "id": "ZpDVlhn2Mc0b"
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining a function to perform all the tasks above so that we can just pass the\n",
        "#column name(label) and get the trained model for each label\n",
        "def model_builder(column_for_model):\n",
        "    #Declare a global variable\n",
        "    global dict_accuracies\n",
        "    #print the name of column being trained\n",
        "    print(f\"running for {column_for_model}\")\n",
        "    #Define the model name\n",
        "    MODEL_NAME = f\"bert_lstm_-_{column_for_model}\"\n",
        "\n",
        "    #Load the model according to the condition if it is a question label or answer label\n",
        "    X_model = X_questions if column_for_model.startswith(\"question_\") else X_answers\n",
        "\n",
        "    #Define the max length based on if it is question only model or question-answer piar model\n",
        "    MODEL_MAX_LENGTH = 3 if column_for_model.startswith(\"question_\") else 4\n",
        "\n",
        "    #Check if the data is balanced amd according implement oversampling method\n",
        "    if df_train[column_for_model].value_counts(normalize = True).iloc[0] > 0.85:\n",
        "        X_resampled, y_resampled = array_oversampler(X_model.reshape(total_rows, -1), Y[:,cols.index(column_for_model)])\n",
        "    else:\n",
        "        X_resampled, y_resampled = X_model, Y[:,cols.index(column_for_model)]\n",
        "    \n",
        "    #Reshape the data to required shape and attributes for both training data and labels\n",
        "    X_resampled = X_resampled.reshape(-1, MODEL_MAX_LENGTH, 768)\n",
        "    y_resampled = pd.get_dummies(y_resampled).values\n",
        "\n",
        "    #Generate Train-Test Sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_resampled,y_resampled, test_size = 0.25, random_state = 42)\n",
        "\n",
        "    #Define the max length based on if it is question only model or question-answer piar model\n",
        "    MODEL_MAX_LENGTH = 3 if column_for_model.startswith(\"question_\") else 4\n",
        "    lstm_out = 64 \n",
        "    # embid_dim = embedding_width # This needs to match the width of our gloVe vectors\n",
        "\n",
        "    #Initilize the model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # The big difference here is that the embedding values are set to not trainable\n",
        "    # model.add(Embedding(vocab_size, embid_dim, input_length =X.shape[1], weights = [embedding_matrix] , trainable = False))\n",
        "    model.add(Bidirectional(LSTM(lstm_out, dropout=0.2), input_shape=(MODEL_MAX_LENGTH,768)))\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2, activation = 'sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    #assign the model batch size\n",
        "    batch_size = 64\n",
        "    #Compile the model with appropriate arguments\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "    ##Fit the model to get training and validation accuracy\n",
        "    history = model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1, validation_data =(X_test, Y_test))\n",
        "    #print the necessary details\n",
        "    print()\n",
        "    print(column_for_model, end=\"\\n\\n\")\n",
        "    print(f\"Last Layer Training Accuracy : {history.history['accuracy'][-1]:.2%}\")\n",
        "    print(f\"Last Layer Validation Accuracy : {history.history['val_accuracy'][-1]:.2%}\")\n",
        "    #append the results of the model to dictonary\n",
        "    dict_accuracies[column_for_model]['training_accuracy'] = history.history['accuracy'][-1]\n",
        "    dict_accuracies[column_for_model]['validation_accuracy'] = history.history['val_accuracy'][-1]\n",
        "    print(\"\\n\\n\\n\")\n",
        "    #Save the model to be reused\n",
        "    model.save(f\"/content/drive/MyDrive/NLP_Project/Trained_Models/{MODEL_NAME}\")\n"
      ],
      "metadata": {
        "id": "LFton8TR09CR"
      },
      "id": "LFton8TR09CR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL TRAINING LOOP"
      ],
      "metadata": {
        "id": "e3lPOQ8MMks4"
      },
      "id": "e3lPOQ8MMks4"
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dictonary\n",
        "dict_accuracies = defaultdict(dict)\n",
        "#Iterate over the columns and build models\n",
        "for col in tqdm(cols[:]):\n",
        "    model_builder(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f6db089930294e5c9041e12b05102260"
          ]
        },
        "id": "rfKWBJDP2kxO",
        "outputId": "c6b30e15-195b-404c-bd8a-eaf83be378f3"
      },
      "id": "rfKWBJDP2kxO",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6db089930294e5c9041e12b05102260",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_asker_intent_understanding\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_32 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "83/83 [==============================] - 7s 18ms/step - loss: 0.4447 - accuracy: 0.8386 - val_loss: 0.4036 - val_accuracy: 0.8618\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.4298 - accuracy: 0.8471 - val_loss: 0.3991 - val_accuracy: 0.8601\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.4188 - accuracy: 0.8483 - val_loss: 0.3789 - val_accuracy: 0.8623\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.4007 - accuracy: 0.8486 - val_loss: 0.3700 - val_accuracy: 0.8578\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 1s 11ms/step - loss: 0.3801 - accuracy: 0.8490 - val_loss: 0.3486 - val_accuracy: 0.8640\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.3698 - accuracy: 0.8532 - val_loss: 0.3393 - val_accuracy: 0.8623\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 1s 12ms/step - loss: 0.3438 - accuracy: 0.8507 - val_loss: 0.3159 - val_accuracy: 0.8674\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 0.3238 - accuracy: 0.8598 - val_loss: 0.3082 - val_accuracy: 0.8725\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.3255 - accuracy: 0.8615 - val_loss: 0.2850 - val_accuracy: 0.8850\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.2985 - accuracy: 0.8675 - val_loss: 0.2548 - val_accuracy: 0.8861\n",
            "\n",
            "question_asker_intent_understanding\n",
            "\n",
            "Last Layer Training Accuracy : 86.75%\n",
            "Last Layer Validation Accuracy : 88.61%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_187_layer_call_fn, lstm_cell_187_layer_call_and_return_conditional_losses, lstm_cell_188_layer_call_fn, lstm_cell_188_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_body_critical\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_33 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 6s 19ms/step - loss: 0.6704 - accuracy: 0.6054 - val_loss: 0.6515 - val_accuracy: 0.6204\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6350 - accuracy: 0.6405 - val_loss: 0.6382 - val_accuracy: 0.6553\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6053 - accuracy: 0.6749 - val_loss: 0.5710 - val_accuracy: 0.7053\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5884 - accuracy: 0.7013 - val_loss: 0.5664 - val_accuracy: 0.7184\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5798 - accuracy: 0.7059 - val_loss: 0.5598 - val_accuracy: 0.7171\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5705 - accuracy: 0.7144 - val_loss: 0.5559 - val_accuracy: 0.7164\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5683 - accuracy: 0.7133 - val_loss: 0.5505 - val_accuracy: 0.7217\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5676 - accuracy: 0.7192 - val_loss: 0.5529 - val_accuracy: 0.7230\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5594 - accuracy: 0.7203 - val_loss: 0.5504 - val_accuracy: 0.7250\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5651 - accuracy: 0.7122 - val_loss: 0.5548 - val_accuracy: 0.7263\n",
            "\n",
            "question_body_critical\n",
            "\n",
            "Last Layer Training Accuracy : 71.22%\n",
            "Last Layer Validation Accuracy : 72.63%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_190_layer_call_fn, lstm_cell_190_layer_call_and_return_conditional_losses, lstm_cell_191_layer_call_fn, lstm_cell_191_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_conversational\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_34 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 7s 17ms/step - loss: 0.4167 - accuracy: 0.8480 - val_loss: 0.3917 - val_accuracy: 0.8433\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3836 - accuracy: 0.8523 - val_loss: 0.4021 - val_accuracy: 0.8433\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3653 - accuracy: 0.8525 - val_loss: 0.3454 - val_accuracy: 0.8445\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3374 - accuracy: 0.8572 - val_loss: 0.3255 - val_accuracy: 0.8650\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3310 - accuracy: 0.8628 - val_loss: 0.3116 - val_accuracy: 0.8609\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3221 - accuracy: 0.8587 - val_loss: 0.3058 - val_accuracy: 0.8644\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.3138 - accuracy: 0.8605 - val_loss: 0.3360 - val_accuracy: 0.8656\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3209 - accuracy: 0.8607 - val_loss: 0.3391 - val_accuracy: 0.8597\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.3134 - accuracy: 0.8619 - val_loss: 0.4073 - val_accuracy: 0.8474\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3214 - accuracy: 0.8636 - val_loss: 0.3030 - val_accuracy: 0.8597\n",
            "\n",
            "question_conversational\n",
            "\n",
            "Last Layer Training Accuracy : 86.36%\n",
            "Last Layer Validation Accuracy : 85.97%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_193_layer_call_fn, lstm_cell_193_layer_call_and_return_conditional_losses, lstm_cell_194_layer_call_fn, lstm_cell_194_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_expect_short_answer\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_35 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 7s 18ms/step - loss: 0.5388 - accuracy: 0.7774 - val_loss: 0.5263 - val_accuracy: 0.7776\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5254 - accuracy: 0.7828 - val_loss: 0.5250 - val_accuracy: 0.7776\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5234 - accuracy: 0.7828 - val_loss: 0.5249 - val_accuracy: 0.7776\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5208 - accuracy: 0.7828 - val_loss: 0.5276 - val_accuracy: 0.7776\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5219 - accuracy: 0.7828 - val_loss: 0.5291 - val_accuracy: 0.7776\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5214 - accuracy: 0.7828 - val_loss: 0.5282 - val_accuracy: 0.7776\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5221 - accuracy: 0.7828 - val_loss: 0.5250 - val_accuracy: 0.7776\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5208 - accuracy: 0.7828 - val_loss: 0.5295 - val_accuracy: 0.7776\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5214 - accuracy: 0.7828 - val_loss: 0.5259 - val_accuracy: 0.7776\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5194 - accuracy: 0.7828 - val_loss: 0.5335 - val_accuracy: 0.7776\n",
            "\n",
            "question_expect_short_answer\n",
            "\n",
            "Last Layer Training Accuracy : 78.28%\n",
            "Last Layer Validation Accuracy : 77.76%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_196_layer_call_fn, lstm_cell_196_layer_call_and_return_conditional_losses, lstm_cell_197_layer_call_fn, lstm_cell_197_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_fact_seeking\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_36 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 7s 18ms/step - loss: 0.5117 - accuracy: 0.7969 - val_loss: 0.4818 - val_accuracy: 0.8164\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5093 - accuracy: 0.7997 - val_loss: 0.4910 - val_accuracy: 0.8164\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5084 - accuracy: 0.7997 - val_loss: 0.4778 - val_accuracy: 0.8164\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5049 - accuracy: 0.7997 - val_loss: 0.4802 - val_accuracy: 0.8164\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5025 - accuracy: 0.7997 - val_loss: 0.4725 - val_accuracy: 0.8164\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5021 - accuracy: 0.7997 - val_loss: 0.4706 - val_accuracy: 0.8164\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5021 - accuracy: 0.7997 - val_loss: 0.4712 - val_accuracy: 0.8164\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4996 - accuracy: 0.7997 - val_loss: 0.4691 - val_accuracy: 0.8164\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4936 - accuracy: 0.7997 - val_loss: 0.4873 - val_accuracy: 0.8164\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4937 - accuracy: 0.7997 - val_loss: 0.4665 - val_accuracy: 0.8164\n",
            "\n",
            "question_fact_seeking\n",
            "\n",
            "Last Layer Training Accuracy : 79.97%\n",
            "Last Layer Validation Accuracy : 81.64%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_199_layer_call_fn, lstm_cell_199_layer_call_and_return_conditional_losses, lstm_cell_200_layer_call_fn, lstm_cell_200_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_has_commonly_accepted_answer\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_37 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 8s 19ms/step - loss: 0.4615 - accuracy: 0.8287 - val_loss: 0.4426 - val_accuracy: 0.8421\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.8375 - val_loss: 0.4208 - val_accuracy: 0.8421\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4357 - accuracy: 0.8375 - val_loss: 0.4181 - val_accuracy: 0.8421\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4335 - accuracy: 0.8375 - val_loss: 0.4098 - val_accuracy: 0.8421\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4279 - accuracy: 0.8375 - val_loss: 0.4038 - val_accuracy: 0.8421\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4144 - accuracy: 0.8375 - val_loss: 0.4114 - val_accuracy: 0.8421\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4129 - accuracy: 0.8375 - val_loss: 0.3951 - val_accuracy: 0.8421\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4141 - accuracy: 0.8375 - val_loss: 0.4266 - val_accuracy: 0.8421\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.4135 - accuracy: 0.8375 - val_loss: 0.3991 - val_accuracy: 0.8421\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.4075 - accuracy: 0.8375 - val_loss: 0.3899 - val_accuracy: 0.8421\n",
            "\n",
            "question_has_commonly_accepted_answer\n",
            "\n",
            "Last Layer Training Accuracy : 83.75%\n",
            "Last Layer Validation Accuracy : 84.21%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_202_layer_call_fn, lstm_cell_202_layer_call_and_return_conditional_losses, lstm_cell_203_layer_call_fn, lstm_cell_203_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_interestingness_others\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_38 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 7s 18ms/step - loss: 0.5880 - accuracy: 0.7309 - val_loss: 0.5608 - val_accuracy: 0.7474\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5762 - accuracy: 0.7372 - val_loss: 0.5564 - val_accuracy: 0.7474\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5683 - accuracy: 0.7372 - val_loss: 0.5576 - val_accuracy: 0.7474\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5728 - accuracy: 0.7372 - val_loss: 0.5510 - val_accuracy: 0.7474\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5634 - accuracy: 0.7372 - val_loss: 0.5433 - val_accuracy: 0.7474\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5551 - accuracy: 0.7372 - val_loss: 0.5387 - val_accuracy: 0.7474\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5594 - accuracy: 0.7372 - val_loss: 0.5734 - val_accuracy: 0.7474\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5577 - accuracy: 0.7372 - val_loss: 0.5399 - val_accuracy: 0.7474\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5502 - accuracy: 0.7372 - val_loss: 0.5373 - val_accuracy: 0.7474\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.5372 - val_accuracy: 0.7474\n",
            "\n",
            "question_interestingness_others\n",
            "\n",
            "Last Layer Training Accuracy : 73.72%\n",
            "Last Layer Validation Accuracy : 74.74%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_205_layer_call_fn, lstm_cell_205_layer_call_and_return_conditional_losses, lstm_cell_206_layer_call_fn, lstm_cell_206_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_interestingness_self\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_39 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 6s 18ms/step - loss: 0.6639 - accuracy: 0.5889 - val_loss: 0.6278 - val_accuracy: 0.6638\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6279 - accuracy: 0.6510 - val_loss: 0.6338 - val_accuracy: 0.6901\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6063 - accuracy: 0.6802 - val_loss: 0.5926 - val_accuracy: 0.6980\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5889 - accuracy: 0.7109 - val_loss: 0.5790 - val_accuracy: 0.7224\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5808 - accuracy: 0.7148 - val_loss: 0.5819 - val_accuracy: 0.7145\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5777 - accuracy: 0.7216 - val_loss: 0.5788 - val_accuracy: 0.7151\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5809 - accuracy: 0.7135 - val_loss: 0.5993 - val_accuracy: 0.6961\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5872 - accuracy: 0.7043 - val_loss: 0.5770 - val_accuracy: 0.7283\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7313 - val_loss: 0.5754 - val_accuracy: 0.7237\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5714 - accuracy: 0.7238 - val_loss: 0.5709 - val_accuracy: 0.7224\n",
            "\n",
            "question_interestingness_self\n",
            "\n",
            "Last Layer Training Accuracy : 72.38%\n",
            "Last Layer Validation Accuracy : 72.24%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_208_layer_call_fn, lstm_cell_208_layer_call_and_return_conditional_losses, lstm_cell_209_layer_call_fn, lstm_cell_209_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_multi_intent\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_40 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 6s 18ms/step - loss: 0.5433 - accuracy: 0.7754 - val_loss: 0.5383 - val_accuracy: 0.7678\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7774 - val_loss: 0.5325 - val_accuracy: 0.7678\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5192 - accuracy: 0.7774 - val_loss: 0.5280 - val_accuracy: 0.7678\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5150 - accuracy: 0.7774 - val_loss: 0.5334 - val_accuracy: 0.7678\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5141 - accuracy: 0.7774 - val_loss: 0.5316 - val_accuracy: 0.7678\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5089 - accuracy: 0.7774 - val_loss: 0.5254 - val_accuracy: 0.7678\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5088 - accuracy: 0.7774 - val_loss: 0.5286 - val_accuracy: 0.7678\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5062 - accuracy: 0.7774 - val_loss: 0.5248 - val_accuracy: 0.7678\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5087 - accuracy: 0.7774 - val_loss: 0.5241 - val_accuracy: 0.7678\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 0.5055 - accuracy: 0.7774 - val_loss: 0.5285 - val_accuracy: 0.7678\n",
            "\n",
            "question_multi_intent\n",
            "\n",
            "Last Layer Training Accuracy : 77.74%\n",
            "Last Layer Validation Accuracy : 76.78%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_211_layer_call_fn, lstm_cell_211_layer_call_and_return_conditional_losses, lstm_cell_212_layer_call_fn, lstm_cell_212_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_not_really_a_question\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_41 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "84/84 [==============================] - 7s 17ms/step - loss: 0.4299 - accuracy: 0.8410 - val_loss: 0.3746 - val_accuracy: 0.8570\n",
            "Epoch 2/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.3281 - accuracy: 0.8773 - val_loss: 0.2426 - val_accuracy: 0.8962\n",
            "Epoch 3/10\n",
            "84/84 [==============================] - 1s 9ms/step - loss: 0.2282 - accuracy: 0.9132 - val_loss: 0.1711 - val_accuracy: 0.9327\n",
            "Epoch 4/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.1395 - accuracy: 0.9441 - val_loss: 0.1083 - val_accuracy: 0.9607\n",
            "Epoch 5/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.0852 - accuracy: 0.9675 - val_loss: 0.0986 - val_accuracy: 0.9602\n",
            "Epoch 6/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.0804 - accuracy: 0.9650 - val_loss: 0.0558 - val_accuracy: 0.9781\n",
            "Epoch 7/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9839 - val_loss: 0.0150 - val_accuracy: 0.9972\n",
            "Epoch 8/10\n",
            "84/84 [==============================] - 1s 9ms/step - loss: 0.0427 - accuracy: 0.9856 - val_loss: 0.0173 - val_accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9800 - val_loss: 0.0212 - val_accuracy: 0.9916\n",
            "Epoch 10/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.0124 - val_accuracy: 0.9972\n",
            "\n",
            "question_not_really_a_question\n",
            "\n",
            "Last Layer Training Accuracy : 99.21%\n",
            "Last Layer Validation Accuracy : 99.72%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_214_layer_call_fn, lstm_cell_214_layer_call_and_return_conditional_losses, lstm_cell_215_layer_call_fn, lstm_cell_215_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_opinion_seeking\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_42 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 6s 19ms/step - loss: 0.6929 - accuracy: 0.5435 - val_loss: 0.6846 - val_accuracy: 0.5592\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6863 - accuracy: 0.5501 - val_loss: 0.6812 - val_accuracy: 0.5592\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6834 - accuracy: 0.5534 - val_loss: 0.6878 - val_accuracy: 0.5342\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6819 - accuracy: 0.5534 - val_loss: 0.6777 - val_accuracy: 0.5638\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6770 - accuracy: 0.5679 - val_loss: 0.6836 - val_accuracy: 0.5322\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6727 - accuracy: 0.5692 - val_loss: 0.7047 - val_accuracy: 0.5599\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6763 - accuracy: 0.5617 - val_loss: 0.6720 - val_accuracy: 0.5618\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.6646 - accuracy: 0.5848 - val_loss: 0.6659 - val_accuracy: 0.5809\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.6660 - accuracy: 0.5835 - val_loss: 0.6634 - val_accuracy: 0.5757\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 0.6625 - accuracy: 0.5846 - val_loss: 0.6620 - val_accuracy: 0.5789\n",
            "\n",
            "question_opinion_seeking\n",
            "\n",
            "Last Layer Training Accuracy : 58.46%\n",
            "Last Layer Validation Accuracy : 57.89%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_217_layer_call_fn, lstm_cell_217_layer_call_and_return_conditional_losses, lstm_cell_218_layer_call_fn, lstm_cell_218_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_choice\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_43 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 7s 18ms/step - loss: 0.5945 - accuracy: 0.7236 - val_loss: 0.5799 - val_accuracy: 0.7342\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5829 - accuracy: 0.7263 - val_loss: 0.5656 - val_accuracy: 0.7342\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5761 - accuracy: 0.7263 - val_loss: 0.5592 - val_accuracy: 0.7342\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5718 - accuracy: 0.7263 - val_loss: 0.5769 - val_accuracy: 0.7342\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5758 - accuracy: 0.7263 - val_loss: 0.5574 - val_accuracy: 0.7342\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5674 - accuracy: 0.7263 - val_loss: 0.5597 - val_accuracy: 0.7342\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5686 - accuracy: 0.7263 - val_loss: 0.5606 - val_accuracy: 0.7342\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5648 - accuracy: 0.7263 - val_loss: 0.5607 - val_accuracy: 0.7342\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5639 - accuracy: 0.7263 - val_loss: 0.5598 - val_accuracy: 0.7342\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5628 - accuracy: 0.7263 - val_loss: 0.5615 - val_accuracy: 0.7342\n",
            "\n",
            "question_type_choice\n",
            "\n",
            "Last Layer Training Accuracy : 72.63%\n",
            "Last Layer Validation Accuracy : 73.42%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_220_layer_call_fn, lstm_cell_220_layer_call_and_return_conditional_losses, lstm_cell_221_layer_call_fn, lstm_cell_221_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_compare\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_44 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "81/81 [==============================] - 8s 17ms/step - loss: 0.4463 - accuracy: 0.8418 - val_loss: 0.4053 - val_accuracy: 0.8513\n",
            "Epoch 2/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3977 - accuracy: 0.8497 - val_loss: 0.3688 - val_accuracy: 0.8513\n",
            "Epoch 3/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3840 - accuracy: 0.8497 - val_loss: 0.3575 - val_accuracy: 0.8513\n",
            "Epoch 4/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3694 - accuracy: 0.8497 - val_loss: 0.3516 - val_accuracy: 0.8513\n",
            "Epoch 5/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3632 - accuracy: 0.8499 - val_loss: 0.3425 - val_accuracy: 0.8513\n",
            "Epoch 6/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3525 - accuracy: 0.8537 - val_loss: 0.3280 - val_accuracy: 0.8582\n",
            "Epoch 7/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3345 - accuracy: 0.8595 - val_loss: 0.3180 - val_accuracy: 0.8704\n",
            "Epoch 8/10\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 0.3288 - accuracy: 0.8601 - val_loss: 0.3335 - val_accuracy: 0.8351\n",
            "Epoch 9/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8653 - val_loss: 0.3540 - val_accuracy: 0.8530\n",
            "Epoch 10/10\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 0.3195 - accuracy: 0.8630 - val_loss: 0.2965 - val_accuracy: 0.8709\n",
            "\n",
            "question_type_compare\n",
            "\n",
            "Last Layer Training Accuracy : 86.30%\n",
            "Last Layer Validation Accuracy : 87.09%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_223_layer_call_fn, lstm_cell_223_layer_call_and_return_conditional_losses, lstm_cell_224_layer_call_fn, lstm_cell_224_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_consequence\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_45 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "84/84 [==============================] - 7s 17ms/step - loss: 0.4368 - accuracy: 0.8458 - val_loss: 0.3987 - val_accuracy: 0.8541\n",
            "Epoch 2/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.3935 - accuracy: 0.8506 - val_loss: 0.3495 - val_accuracy: 0.8608\n",
            "Epoch 3/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.3243 - accuracy: 0.8659 - val_loss: 0.3321 - val_accuracy: 0.8744\n",
            "Epoch 4/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.2923 - accuracy: 0.8811 - val_loss: 0.2720 - val_accuracy: 0.8755\n",
            "Epoch 5/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.2645 - accuracy: 0.8942 - val_loss: 0.2460 - val_accuracy: 0.8997\n",
            "Epoch 6/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.2349 - accuracy: 0.9051 - val_loss: 0.2175 - val_accuracy: 0.9206\n",
            "Epoch 7/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.2263 - accuracy: 0.9100 - val_loss: 0.2056 - val_accuracy: 0.9262\n",
            "Epoch 8/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.1960 - accuracy: 0.9237 - val_loss: 0.1767 - val_accuracy: 0.9330\n",
            "Epoch 9/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.1725 - accuracy: 0.9314 - val_loss: 0.1516 - val_accuracy: 0.9437\n",
            "Epoch 10/10\n",
            "84/84 [==============================] - 1s 8ms/step - loss: 0.1487 - accuracy: 0.9465 - val_loss: 0.1362 - val_accuracy: 0.9425\n",
            "\n",
            "question_type_consequence\n",
            "\n",
            "Last Layer Training Accuracy : 94.65%\n",
            "Last Layer Validation Accuracy : 94.25%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_226_layer_call_fn, lstm_cell_226_layer_call_and_return_conditional_losses, lstm_cell_227_layer_call_fn, lstm_cell_227_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_definition\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_46 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "82/82 [==============================] - 6s 17ms/step - loss: 0.4019 - accuracy: 0.8432 - val_loss: 0.2987 - val_accuracy: 0.8711\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.3115 - accuracy: 0.8659 - val_loss: 0.2469 - val_accuracy: 0.8895\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2741 - accuracy: 0.8812 - val_loss: 0.2546 - val_accuracy: 0.8734\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2761 - accuracy: 0.8791 - val_loss: 0.2287 - val_accuracy: 0.9016\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2585 - accuracy: 0.8914 - val_loss: 0.2063 - val_accuracy: 0.9177\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2425 - accuracy: 0.8968 - val_loss: 0.2053 - val_accuracy: 0.9125\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2420 - accuracy: 0.8979 - val_loss: 0.2044 - val_accuracy: 0.9085\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2288 - accuracy: 0.9077 - val_loss: 0.2357 - val_accuracy: 0.9010\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.2357 - accuracy: 0.9008 - val_loss: 0.1854 - val_accuracy: 0.9212\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 1s 11ms/step - loss: 0.2207 - accuracy: 0.9046 - val_loss: 0.1831 - val_accuracy: 0.9235\n",
            "\n",
            "question_type_definition\n",
            "\n",
            "Last Layer Training Accuracy : 90.46%\n",
            "Last Layer Validation Accuracy : 92.35%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_229_layer_call_fn, lstm_cell_229_layer_call_and_return_conditional_losses, lstm_cell_230_layer_call_fn, lstm_cell_230_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_entity\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_47 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 6s 18ms/step - loss: 0.4389 - accuracy: 0.8392 - val_loss: 0.3890 - val_accuracy: 0.8596\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.4075 - accuracy: 0.8469 - val_loss: 0.3697 - val_accuracy: 0.8596\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.3974 - accuracy: 0.8469 - val_loss: 0.3622 - val_accuracy: 0.8596\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3890 - accuracy: 0.8475 - val_loss: 0.3559 - val_accuracy: 0.8614\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.3798 - accuracy: 0.8487 - val_loss: 0.3505 - val_accuracy: 0.8620\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3722 - accuracy: 0.8487 - val_loss: 0.3449 - val_accuracy: 0.8614\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.3653 - accuracy: 0.8495 - val_loss: 0.3298 - val_accuracy: 0.8596\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.3672 - accuracy: 0.8503 - val_loss: 0.3344 - val_accuracy: 0.8667\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 1s 12ms/step - loss: 0.3533 - accuracy: 0.8531 - val_loss: 0.3102 - val_accuracy: 0.8679\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 1s 12ms/step - loss: 0.3584 - accuracy: 0.8542 - val_loss: 0.3184 - val_accuracy: 0.8649\n",
            "\n",
            "question_type_entity\n",
            "\n",
            "Last Layer Training Accuracy : 85.42%\n",
            "Last Layer Validation Accuracy : 86.49%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_232_layer_call_fn, lstm_cell_232_layer_call_and_return_conditional_losses, lstm_cell_233_layer_call_fn, lstm_cell_233_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_instructions\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_48 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 7s 34ms/step - loss: 0.6452 - accuracy: 0.6150 - val_loss: 0.6382 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5754 - accuracy: 0.7089 - val_loss: 0.6313 - val_accuracy: 0.6467\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 0.5506 - accuracy: 0.7293 - val_loss: 0.5261 - val_accuracy: 0.7572\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5263 - accuracy: 0.7550 - val_loss: 0.4954 - val_accuracy: 0.7618\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5015 - accuracy: 0.7723 - val_loss: 0.5135 - val_accuracy: 0.7487\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7725 - val_loss: 0.4985 - val_accuracy: 0.7599\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 0.4901 - accuracy: 0.7815 - val_loss: 0.5144 - val_accuracy: 0.7526\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 0.5195 - accuracy: 0.7633 - val_loss: 0.4842 - val_accuracy: 0.7724\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 0.4858 - accuracy: 0.7754 - val_loss: 0.4706 - val_accuracy: 0.7849\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 0.4897 - accuracy: 0.7875 - val_loss: 0.4915 - val_accuracy: 0.7697\n",
            "\n",
            "question_type_instructions\n",
            "\n",
            "Last Layer Training Accuracy : 78.75%\n",
            "Last Layer Validation Accuracy : 76.97%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_235_layer_call_fn, lstm_cell_235_layer_call_and_return_conditional_losses, lstm_cell_236_layer_call_fn, lstm_cell_236_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running for question_type_procedure\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_49 (Bidirecti  (None, 128)              426496    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,394\n",
            "Trainable params: 451,394\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "73/73 [==============================] - 7s 19ms/step - loss: 0.4428 - accuracy: 0.8482 - val_loss: 0.4154 - val_accuracy: 0.8536\n",
            "Epoch 2/10\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 0.4326 - accuracy: 0.8488 - val_loss: 0.4150 - val_accuracy: 0.8536\n",
            "Epoch 3/10\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8488 - val_loss: 0.4210 - val_accuracy: 0.8536\n",
            "Epoch 4/10\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4295 - accuracy: 0.8488 - val_loss: 0.4128 - val_accuracy: 0.8536\n",
            "Epoch 5/10\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4292 - accuracy: 0.8488 - val_loss: 0.4130 - val_accuracy: 0.8536\n",
            "Epoch 6/10\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4259 - accuracy: 0.8488 - val_loss: 0.4139 - val_accuracy: 0.8536\n",
            "Epoch 7/10\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 0.4238 - accuracy: 0.8488 - val_loss: 0.4123 - val_accuracy: 0.8536\n",
            "Epoch 8/10\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 0.4244 - accuracy: 0.8488 - val_loss: 0.4166 - val_accuracy: 0.8536\n",
            "Epoch 9/10\n",
            "73/73 [==============================] - 1s 12ms/step - loss: 0.4247 - accuracy: 0.8488 - val_loss: 0.4239 - val_accuracy: 0.8536\n",
            "Epoch 10/10\n",
            "73/73 [==============================] - 1s 12ms/step - loss: 0.4248 - accuracy: 0.8488 - val_loss: 0.4116 - val_accuracy: 0.8536\n",
            "\n",
            "question_type_procedure\n",
            "\n",
            "Last Layer Training Accuracy : 84.88%\n",
            "Last Layer Validation Accuracy : 85.36%\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_238_layer_call_fn, lstm_cell_238_layer_call_and_return_conditional_losses, lstm_cell_239_layer_call_fn, lstm_cell_239_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch[0]['input_ids']\n",
        "# batch[0]['token_type_ids']\n",
        "# batch[0]['attention_mask'].size(),batch[1]['attention_mask'].size(), torch.concat((batch[0]['attention_mask'],batch[1]['attention_mask']), dim=1).size()"
      ],
      "metadata": {
        "id": "r1UxfrQGRMUi"
      },
      "id": "r1UxfrQGRMUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for qa, qb, a, cat\n",
        "#     dataloader : embeddings --> y (any of the 30)\n",
        "# for labels:\n",
        "#     oversample \n",
        "#     model.compile\n",
        "#     model.save(label)\n"
      ],
      "metadata": {
        "id": "bf1qIY5WEkZ4"
      },
      "id": "bf1qIY5WEkZ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTION"
      ],
      "metadata": {
        "id": "lo_b78HGMvM9"
      },
      "id": "lo_b78HGMvM9"
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the test dataset\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/NLP_Project/test.csv\")"
      ],
      "metadata": {
        "id": "f0dCadUlE1_C"
      },
      "id": "f0dCadUlE1_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#View first 6 records\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "5zgwC6soE6Qr"
      },
      "id": "5zgwC6soE6Qr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initilize a dataloader for test dataset\n",
        "dataloader_test = DataLoader(QA_B_dataset(df_test, cols, bert_tokenizer_qt, bert_tokenizer_qb, bert_tokenizer_a, bert_tokenizer_category, is_test=True), batch_size=BATCH_SIZE, collate_fn=custom_collate)"
      ],
      "metadata": {
        "id": "PxcBHd7vFM8W"
      },
      "id": "PxcBHd7vFM8W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.eval()\n",
        "\n",
        "#Create empty lists\n",
        "X_qt = []\n",
        "X_qb = []\n",
        "X_a = []\n",
        "X_c = []\n",
        "\n",
        "#Iterate through the test dataloader\n",
        "for batch in tqdm(dataloader_test):\n",
        "    with torch.no_grad():\n",
        "      output_type = 'pooler_output' # last_hidden_state or pooler_output\n",
        "      #Train the data using bert model (for embed)\n",
        "      out_qt = bert_model(**batch[0].to(device))[output_type].cpu().numpy()\n",
        "      out_qb = bert_model(**batch[1].to(device))[output_type].cpu().numpy()\n",
        "      out_a = bert_model(**batch[2].to(device))[output_type].cpu().numpy()\n",
        "      out_c = bert_model(**batch[3].to(device))[output_type].cpu().numpy()\n",
        "    #Append the data\n",
        "    X_qt.append(out_qt)\n",
        "    X_qb.append(out_qb)\n",
        "    X_a.append(out_a)\n",
        "    X_c.append(out_c)"
      ],
      "metadata": {
        "id": "djtDJYJ1FM5b"
      },
      "id": "djtDJYJ1FM5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate the results and reshape them required input shape\n",
        "X_qt = np.concatenate(X_qt).reshape(-1,1,768)\n",
        "X_qb = np.concatenate(X_qb).reshape(-1,1,768)\n",
        "X_a = np.concatenate(X_a).reshape(-1,1,768)\n",
        "X_c = np.concatenate(X_c).reshape(-1,1,768)"
      ],
      "metadata": {
        "id": "3bin_yZvH6zH"
      },
      "id": "3bin_yZvH6zH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for questions only\n",
        "X_questions_test = np.concatenate([X_c, X_qt, X_qb], axis = 1)\n",
        "\n",
        "# for question answer pair\n",
        "X_answers_test = np.concatenate([X_c, X_qt, X_qb, X_a], axis = 1)"
      ],
      "metadata": {
        "id": "rxsuyqpiHtKQ"
      },
      "id": "rxsuyqpiHtKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a model prediction function which uploads the trained model based on the \n",
        "#label and makes prediction on the test data\n",
        "def model_predict(column_for_model):\n",
        "    #Define a global variable\n",
        "    global result_dict\n",
        "    #Print the column that is being predicted\n",
        "    print(f\"running predictions for {column_for_model}\")\n",
        "    #Import the traind model for the label to be predicted\n",
        "    MODEL_NAME = f\"/content/drive/MyDrive/NLP_Project/Trained_Models/bert_lstm_-_{column_for_model}\"\n",
        "\n",
        "    #Load the model according to the condition if it is a question label or answer label\n",
        "    X_model = X_questions_test if column_for_model.startswith(\"question_\") else X_answers_test\n",
        "\n",
        "    #Define the max length based on if it is question only model or question-answer piar model\n",
        "    MODEL_MAX_LENGTH = 3 if column_for_model.startswith(\"question_\") else 4\n",
        "\n",
        "    #Since we don't have any labels for the data\n",
        "    X_resampled = X_model\n",
        "    \n",
        "    #Reshape to the required input shape\n",
        "    X_resampled = X_resampled.reshape(-1, MODEL_MAX_LENGTH, 768)\n",
        "\n",
        "    #Define the max length based on if it is question only model or question-answer piar model\n",
        "    MODEL_MAX_LENGTH = 3 if column_for_model.startswith(\"question_\") else 4\n",
        "    lstm_out = 64 \n",
        "\n",
        "    #Load the model\n",
        "    model = keras.models.load_model(MODEL_NAME)\n",
        "\n",
        "    #Define the model batch size\n",
        "    batch_size = 64\n",
        "\n",
        "    #Make the prediction using the trained model\n",
        "    Y_pred = model.predict(X_resampled, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    #Taking the label with max probability\n",
        "    Y_pred = Y_pred.argmax(axis = 1)\n",
        "\n",
        "    #Return the predicted results\n",
        "    return Y_pred"
      ],
      "metadata": {
        "id": "psDSnwhPFM3D"
      },
      "id": "psDSnwhPFM3D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate an empty dictionary\n",
        "result_dict = {}\n",
        "\n",
        "#Iterate through the columns and store the predictions in the dictionary\n",
        "for col in tqdm(cols): \n",
        "    result_dict[col] = model_predict(col)"
      ],
      "metadata": {
        "id": "-Yk2aAqZE6Ll"
      },
      "id": "-Yk2aAqZE6Ll",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe of the dictionary\n",
        "df_pred = pd.DataFrame(result_dict)"
      ],
      "metadata": {
        "id": "wtiY8KRQE6DM"
      },
      "id": "wtiY8KRQE6DM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the predicted value counts for each label\n",
        "for col in cols:\n",
        "    display(df_pred[col].value_counts())"
      ],
      "metadata": {
        "id": "0yWIzIxvK1F3"
      },
      "id": "0yWIzIxvK1F3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RESULT ANALYSIS"
      ],
      "metadata": {
        "id": "xw4qRVFuD9cY"
      },
      "id": "xw4qRVFuD9cY"
    },
    {
      "cell_type": "code",
      "source": [
        "#Create adataframe of all the training and validation accuracies\n",
        "res_df = pd.DataFrame(dict_accuracies).T"
      ],
      "metadata": {
        "id": "IQQf9RkQE6AT"
      },
      "id": "IQQf9RkQE6AT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a round function to convert the accuracies to percentages and the round\n",
        "#them to 2 decimal places\n",
        "round_fn = lambda x: round(x*100, 2)\n",
        "#Apply the dunction to the dataframe accuracy columns\n",
        "res_df[\"training_accuracy\"] = res_df[\"training_accuracy\"].apply(round_fn)\n",
        "res_df[\"validation_accuracy\"] = res_df[\"validation_accuracy\"].apply(round_fn)"
      ],
      "metadata": {
        "id": "EXAjiAVaE59g"
      },
      "id": "EXAjiAVaE59g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#View the dataset\n",
        "res_df"
      ],
      "metadata": {
        "id": "DAgxwkSTE55X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "a2446a87-b5d1-4a17-9fe3-346e2423210f"
      },
      "id": "DAgxwkSTE55X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       training_accuracy  validation_accuracy\n",
              "question_asker_intent_understanding                86.75                88.61\n",
              "question_body_critical                             71.22                72.63\n",
              "question_conversational                            86.36                85.97\n",
              "question_expect_short_answer                       78.28                77.76\n",
              "question_fact_seeking                              79.97                81.64\n",
              "question_has_commonly_accepted_answer              83.75                84.21\n",
              "question_interestingness_others                    73.72                74.74\n",
              "question_interestingness_self                      72.38                72.24\n",
              "question_multi_intent                              77.74                76.78\n",
              "question_not_really_a_question                     99.21                99.72\n",
              "question_opinion_seeking                           58.46                57.89\n",
              "question_type_choice                               72.63                73.42\n",
              "question_type_compare                              86.30                87.09\n",
              "question_type_consequence                          94.65                94.25\n",
              "question_type_definition                           90.46                92.35\n",
              "question_type_entity                               85.42                86.49\n",
              "question_type_instructions                         78.75                76.97\n",
              "question_type_procedure                            84.88                85.36\n",
              "question_type_reason_explanation                   65.67                67.57\n",
              "question_type_spelling                             99.72                99.61\n",
              "question_well_written                              84.67                86.14\n",
              "answer_helpful                                     95.12                96.17\n",
              "answer_level_of_information                        84.80                85.59\n",
              "answer_plausible                                   99.51                99.83\n",
              "answer_relevance                                   99.29                99.72\n",
              "answer_satisfaction                                87.08                88.30\n",
              "answer_type_instructions                           77.41                79.14\n",
              "answer_type_procedure                              84.84                85.50\n",
              "answer_type_reason_explanation                     70.04                68.09\n",
              "answer_well_written                                99.48                99.66"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2da0796-7f17-4a2a-ab0d-eacd61ae4884\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>training_accuracy</th>\n",
              "      <th>validation_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>question_asker_intent_understanding</th>\n",
              "      <td>86.75</td>\n",
              "      <td>88.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_body_critical</th>\n",
              "      <td>71.22</td>\n",
              "      <td>72.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_conversational</th>\n",
              "      <td>86.36</td>\n",
              "      <td>85.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_expect_short_answer</th>\n",
              "      <td>78.28</td>\n",
              "      <td>77.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_fact_seeking</th>\n",
              "      <td>79.97</td>\n",
              "      <td>81.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_has_commonly_accepted_answer</th>\n",
              "      <td>83.75</td>\n",
              "      <td>84.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_interestingness_others</th>\n",
              "      <td>73.72</td>\n",
              "      <td>74.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_interestingness_self</th>\n",
              "      <td>72.38</td>\n",
              "      <td>72.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_multi_intent</th>\n",
              "      <td>77.74</td>\n",
              "      <td>76.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_not_really_a_question</th>\n",
              "      <td>99.21</td>\n",
              "      <td>99.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_opinion_seeking</th>\n",
              "      <td>58.46</td>\n",
              "      <td>57.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_choice</th>\n",
              "      <td>72.63</td>\n",
              "      <td>73.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_compare</th>\n",
              "      <td>86.30</td>\n",
              "      <td>87.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_consequence</th>\n",
              "      <td>94.65</td>\n",
              "      <td>94.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_definition</th>\n",
              "      <td>90.46</td>\n",
              "      <td>92.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_entity</th>\n",
              "      <td>85.42</td>\n",
              "      <td>86.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_instructions</th>\n",
              "      <td>78.75</td>\n",
              "      <td>76.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_procedure</th>\n",
              "      <td>84.88</td>\n",
              "      <td>85.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_reason_explanation</th>\n",
              "      <td>65.67</td>\n",
              "      <td>67.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_type_spelling</th>\n",
              "      <td>99.72</td>\n",
              "      <td>99.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_well_written</th>\n",
              "      <td>84.67</td>\n",
              "      <td>86.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_helpful</th>\n",
              "      <td>95.12</td>\n",
              "      <td>96.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_level_of_information</th>\n",
              "      <td>84.80</td>\n",
              "      <td>85.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_plausible</th>\n",
              "      <td>99.51</td>\n",
              "      <td>99.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_relevance</th>\n",
              "      <td>99.29</td>\n",
              "      <td>99.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_satisfaction</th>\n",
              "      <td>87.08</td>\n",
              "      <td>88.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_type_instructions</th>\n",
              "      <td>77.41</td>\n",
              "      <td>79.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_type_procedure</th>\n",
              "      <td>84.84</td>\n",
              "      <td>85.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_type_reason_explanation</th>\n",
              "      <td>70.04</td>\n",
              "      <td>68.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_well_written</th>\n",
              "      <td>99.48</td>\n",
              "      <td>99.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2da0796-7f17-4a2a-ab0d-eacd61ae4884')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2da0796-7f17-4a2a-ab0d-eacd61ae4884 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2da0796-7f17-4a2a-ab0d-eacd61ae4884');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWG_SOFhE5vN"
      },
      "id": "VWG_SOFhE5vN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9922406d",
        "c2d9e8ad",
        "S7se8khhLtIQ",
        "zKEh6awJL1BW",
        "ITAif9l7L_lM",
        "XVq1QEhfMHGW",
        "29h-fDZ6MRuE",
        "ZpDVlhn2Mc0b",
        "e3lPOQ8MMks4"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5005e4732fe444fab84551e7a114824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7ece6c2be254d47a51e842bd6fd0b4c",
              "IPY_MODEL_ed0380158a1b4f3b993776b0989f6fec",
              "IPY_MODEL_188292fae57e40b39bd3e8faa9fa07e9"
            ],
            "layout": "IPY_MODEL_b9d489cfc5f24b0882195f618082b4d8"
          }
        },
        "e7ece6c2be254d47a51e842bd6fd0b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9287103ca82f4f7fbd77b8d1e44bac43",
            "placeholder": "​",
            "style": "IPY_MODEL_48099e182768436d89727239ce8f3e88",
            "value": "100%"
          }
        },
        "ed0380158a1b4f3b993776b0989f6fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b1c841bb7f4d3ca7336a6558726e6e",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c832da7003a4590ac39f5ab2df182d8",
            "value": 95
          }
        },
        "188292fae57e40b39bd3e8faa9fa07e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d3849bbf574d398d91ace3689d8fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_4e99b019339145f6a413eed225d14dac",
            "value": " 95/95 [02:45&lt;00:00,  1.70s/it]"
          }
        },
        "b9d489cfc5f24b0882195f618082b4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9287103ca82f4f7fbd77b8d1e44bac43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48099e182768436d89727239ce8f3e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b1c841bb7f4d3ca7336a6558726e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c832da7003a4590ac39f5ab2df182d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d3849bbf574d398d91ace3689d8fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e99b019339145f6a413eed225d14dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}